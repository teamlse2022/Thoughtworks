{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e1413db",
   "metadata": {},
   "source": [
    "## Note: Please ensure you run this workbook from the same folder as where the underlying data files are stored in your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc98439",
   "metadata": {},
   "source": [
    "# Preparing the Environment for Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76280001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of Models, Libraries & Date Parsing Functionality \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm \n",
    "import nltk\n",
    "import os\n",
    "import string   \n",
    "import re\n",
    "import math\n",
    "import squarify\n",
    "import plotly.express as px\n",
    "import requests\n",
    "\n",
    "# Copy the YAML file and Twitter keys over to this Jupyter Notebook before you start to work.\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from twitter import *\n",
    "import tweepy\n",
    "\n",
    "from pywaffle import Waffle\n",
    "from datetime import datetime\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "from scipy.stats import norm\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.ndimage import gaussian_gradient_magnitude\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setting up a date parser using a private funciton, lambda\n",
    "# This will give us the dates in a format we require for aggregation & indexation\n",
    "d_parser = lambda x: pd.datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d5011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file(s) for count data only.\n",
    "ny_counts = pd.read_csv('NY_Bicycle_Counts.csv', parse_dates=['date'], date_parser=d_parser)\n",
    "inner_london = pd.read_csv('Inner_London.csv')\n",
    "central_london = pd.read_csv('Central_London.csv')\n",
    "outer_london = pd.read_csv('Outer_London.csv')\n",
    "sydney_counts = pd.read_csv('Sydney_count_surveys.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646b402",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424db8fc",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a2b623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4167507 entries, 0 to 4167506\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Dtype         \n",
      "---  ------  -----         \n",
      " 0   id      int64         \n",
      " 1   date    datetime64[ns]\n",
      " 2   counts  int64         \n",
      " 3   status  int64         \n",
      "dtypes: datetime64[ns](1), int64(3)\n",
      "memory usage: 127.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 615168 entries, 0 to 615167\n",
      "Data columns (total 13 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Survey wave (year)          523776 non-null  float64\n",
      " 1   Site ID                     523776 non-null  object \n",
      " 2   Location                    523776 non-null  object \n",
      " 3   Survey date                 521024 non-null  object \n",
      " 4   Weather                     519102 non-null  object \n",
      " 5   Time                        523770 non-null  object \n",
      " 6   Period                      523770 non-null  object \n",
      " 7   Direction                   523776 non-null  object \n",
      " 8   Start hour                  523770 non-null  float64\n",
      " 9   Start minute                523770 non-null  float64\n",
      " 10  Number of private cycles    523776 non-null  float64\n",
      " 11  Number of cycle hire bikes  523776 non-null  float64\n",
      " 12  Total cycles                523776 non-null  float64\n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 61.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048366 entries, 0 to 1048365\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   Survey wave (calendar quarter)  758163 non-null  object \n",
      " 1   Equivalent financial quarter    758163 non-null  object \n",
      " 2   Site ID                         758163 non-null  object \n",
      " 3   Location                        758163 non-null  object \n",
      " 4   Survey date                     748007 non-null  object \n",
      " 5   Weather                         746329 non-null  object \n",
      " 6   Time                            758163 non-null  object \n",
      " 7   Period                          758163 non-null  object \n",
      " 8   Direction                       758163 non-null  object \n",
      " 9   Start hour                      758163 non-null  float64\n",
      " 10  Start minute                    758163 non-null  float64\n",
      " 11  Number of private cycles        758099 non-null  float64\n",
      " 12  Number of cycle hire bikes      758099 non-null  float64\n",
      " 13  Total cycles                    758163 non-null  float64\n",
      " 14  Unnamed: 14                     0 non-null       float64\n",
      " 15  Unnamed: 15                     0 non-null       float64\n",
      " 16  Unnamed: 16                     0 non-null       float64\n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 136.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 375660 entries, 0 to 375659\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   Survey wave (year)        375660 non-null  int64 \n",
      " 1   Site ID                   375660 non-null  object\n",
      " 2   Location                  375660 non-null  object\n",
      " 3   Survey date               374492 non-null  object\n",
      " 4   Weather                   374692 non-null  object\n",
      " 5   Time                      375660 non-null  object\n",
      " 6   Period                    375660 non-null  object\n",
      " 7   Direction                 375660 non-null  object\n",
      " 8   Start hour                375660 non-null  int64 \n",
      " 9   Start minute              375660 non-null  int64 \n",
      " 10  Number of male cycles     375660 non-null  int64 \n",
      " 11  Number of female cycles   375660 non-null  int64 \n",
      " 12  Number of unknown cycles  375660 non-null  int64 \n",
      " 13  Total cycles              375660 non-null  int64 \n",
      "dtypes: int64(7), object(7)\n",
      "memory usage: 40.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2215 entries, 0 to 2214\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   SiteID      2215 non-null   int64 \n",
      " 1   Month       2215 non-null   object\n",
      " 2   Year        2215 non-null   int64 \n",
      " 3   TotalCount  2215 non-null   int64 \n",
      " 4   ObjectId2   2215 non-null   int64 \n",
      " 5   Time_0600   2215 non-null   int64 \n",
      " 6   Time_0700   2215 non-null   int64 \n",
      " 7   Time_0800   2215 non-null   int64 \n",
      " 8   Time_1600   2215 non-null   int64 \n",
      " 9   Time_1700   2215 non-null   int64 \n",
      " 10  Time_1800   2215 non-null   int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 190.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# View the DataFrame, metadata, shape\n",
    "ny_counts.info()\n",
    "inner_london.info()\n",
    "central_london.info()\n",
    "outer_london.info()\n",
    "sydney_counts.info()\n",
    "\n",
    "# ny_counts is a large but simple Df containing the number of bicycles passing through a counter\n",
    "# No missing data in ny_counts  \n",
    "# Non-Null values for London DataFrames(Df) across all columns dont add up. \n",
    "# Implies missing data.\n",
    "# Will need to explore further.\n",
    "# Central London is another very large Df\n",
    "# Large Dfs need to be trimmed for unncessary data to reduce strain on memory use.\n",
    "# Sydney observations are just aggregated by month and SiteID\n",
    "# Sydney observations run for selected hours and not all day (looks like peak hours only)\n",
    "# Sydney also has no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78435958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survey wave (year)            91392\n",
       "Site ID                       91392\n",
       "Location                      91392\n",
       "Survey date                   94144\n",
       "Weather                       96066\n",
       "Time                          91398\n",
       "Period                        91398\n",
       "Direction                     91392\n",
       "Start hour                    91398\n",
       "Start minute                  91398\n",
       "Number of private cycles      91392\n",
       "Number of cycle hire bikes    91392\n",
       "Total cycles                  91392\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get more precise handle on missing values in each Df\n",
    "inner_london.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b38972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survey wave (calendar quarter)     290203\n",
       "Equivalent financial quarter       290203\n",
       "Site ID                            290203\n",
       "Location                           290203\n",
       "Survey date                        300359\n",
       "Weather                            302037\n",
       "Time                               290203\n",
       "Period                             290203\n",
       "Direction                          290203\n",
       "Start hour                         290203\n",
       "Start minute                       290203\n",
       "Number of private cycles           290267\n",
       "Number of cycle hire bikes         290267\n",
       "Total cycles                       290203\n",
       "Unnamed: 14                       1048366\n",
       "Unnamed: 15                       1048366\n",
       "Unnamed: 16                       1048366\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get more precise handle on missing values in each Df\n",
    "central_london.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae33a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survey wave (year)             0\n",
       "Site ID                        0\n",
       "Location                       0\n",
       "Survey date                 1168\n",
       "Weather                      968\n",
       "Time                           0\n",
       "Period                         0\n",
       "Direction                      0\n",
       "Start hour                     0\n",
       "Start minute                   0\n",
       "Number of male cycles          0\n",
       "Number of female cycles        0\n",
       "Number of unknown cycles       0\n",
       "Total cycles                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get more precise handle on missing values in each Df\n",
    "outer_london.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8636f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>counts</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100009425</td>\n",
       "      <td>2022-06-24 00:00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100009425</td>\n",
       "      <td>2022-06-24 00:15:00</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100009425</td>\n",
       "      <td>2022-06-24 00:30:00</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100009425</td>\n",
       "      <td>2022-06-24 00:45:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100009425</td>\n",
       "      <td>2022-06-24 01:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                date  counts  status\n",
       "0  100009425 2022-06-24 00:00:00      15       0\n",
       "1  100009425 2022-06-24 00:15:00      12       0\n",
       "2  100009425 2022-06-24 00:30:00      14       0\n",
       "3  100009425 2022-06-24 00:45:00       5       0\n",
       "4  100009425 2022-06-24 01:00:00      10       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at samples of the data\n",
    "ny_counts.head(5)\n",
    "\n",
    "# Very sparse but clean data\n",
    "# Id is site Id for where the counter is located\n",
    "# Data runs until mid June 2022. \n",
    "# So data is very recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2689931f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>counts</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4167502</th>\n",
       "      <td>100005020</td>\n",
       "      <td>2012-12-12 02:45:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167503</th>\n",
       "      <td>100005020</td>\n",
       "      <td>2012-12-12 03:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167504</th>\n",
       "      <td>100005020</td>\n",
       "      <td>2012-12-12 03:15:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167505</th>\n",
       "      <td>100005020</td>\n",
       "      <td>2012-12-12 03:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167506</th>\n",
       "      <td>100005020</td>\n",
       "      <td>2012-12-12 03:45:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                date  counts  status\n",
       "4167502  100005020 2012-12-12 02:45:00       3       4\n",
       "4167503  100005020 2012-12-12 03:00:00       2       4\n",
       "4167504  100005020 2012-12-12 03:15:00       3       4\n",
       "4167505  100005020 2012-12-12 03:30:00       1       4\n",
       "4167506  100005020 2012-12-12 03:45:00       2       4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring why NY data is so large.\n",
    "# View Tail to see how long the data runs until\n",
    "ny_counts.tail(5)\n",
    "\n",
    "# Data starts from mid Dec 2012\n",
    "# Need to explore how far the other data sets run until"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b7c299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey wave (year)</th>\n",
       "      <th>Site ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Survey date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Time</th>\n",
       "      <th>Period</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Start hour</th>\n",
       "      <th>Start minute</th>\n",
       "      <th>Number of private cycles</th>\n",
       "      <th>Number of cycle hire bikes</th>\n",
       "      <th>Total cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>INNCY001</td>\n",
       "      <td>Grove Road</td>\n",
       "      <td>mer, 20/05/15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0600 - 0615</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>INNCY001</td>\n",
       "      <td>Grove Road</td>\n",
       "      <td>mer, 20/05/15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0615 - 0630</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>INNCY001</td>\n",
       "      <td>Grove Road</td>\n",
       "      <td>mer, 20/05/15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0630 - 0645</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>INNCY001</td>\n",
       "      <td>Grove Road</td>\n",
       "      <td>mer, 20/05/15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0645 - 0700</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>INNCY001</td>\n",
       "      <td>Grove Road</td>\n",
       "      <td>mer, 20/05/15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0700 - 0715</td>\n",
       "      <td>AM peak (07:00-10:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survey wave (year)   Site ID    Location    Survey date Weather  \\\n",
       "0              2015.0  INNCY001  Grove Road  mer, 20/05/15     Dry   \n",
       "1              2015.0  INNCY001  Grove Road  mer, 20/05/15     Dry   \n",
       "2              2015.0  INNCY001  Grove Road  mer, 20/05/15     Dry   \n",
       "3              2015.0  INNCY001  Grove Road  mer, 20/05/15     Dry   \n",
       "4              2015.0  INNCY001  Grove Road  mer, 20/05/15     Dry   \n",
       "\n",
       "          Time                       Period   Direction  Start hour  \\\n",
       "0  0600 - 0615  Early Morning (06:00-07:00)  Northbound         6.0   \n",
       "1  0615 - 0630  Early Morning (06:00-07:00)  Northbound         6.0   \n",
       "2  0630 - 0645  Early Morning (06:00-07:00)  Northbound         6.0   \n",
       "3  0645 - 0700  Early Morning (06:00-07:00)  Northbound         6.0   \n",
       "4  0700 - 0715        AM peak (07:00-10:00)  Northbound         7.0   \n",
       "\n",
       "   Start minute  Number of private cycles  Number of cycle hire bikes  \\\n",
       "0           0.0                       1.0                         0.0   \n",
       "1          15.0                       2.0                         0.0   \n",
       "2          30.0                       2.0                         0.0   \n",
       "3          45.0                       4.0                         0.0   \n",
       "4           0.0                       4.0                         0.0   \n",
       "\n",
       "   Total cycles  \n",
       "0           1.0  \n",
       "1           2.0  \n",
       "2           2.0  \n",
       "3           4.0  \n",
       "4           4.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at samples of the data\n",
    "inner_london.head(5)\n",
    "\n",
    "# Date has french word in it. Needs to cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6257e7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey wave (calendar quarter)</th>\n",
       "      <th>Equivalent financial quarter</th>\n",
       "      <th>Site ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Survey date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Time</th>\n",
       "      <th>Period</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Start hour</th>\n",
       "      <th>Start minute</th>\n",
       "      <th>Number of private cycles</th>\n",
       "      <th>Number of cycle hire bikes</th>\n",
       "      <th>Total cycles</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014 Q1 (January-March)</td>\n",
       "      <td>2013-14 Q4</td>\n",
       "      <td>CENCY001</td>\n",
       "      <td>Millbank (south of Thorney Street)</td>\n",
       "      <td>ven, 24/01/14</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0600 - 0615</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014 Q1 (January-March)</td>\n",
       "      <td>2013-14 Q4</td>\n",
       "      <td>CENCY001</td>\n",
       "      <td>Millbank (south of Thorney Street)</td>\n",
       "      <td>ven, 24/01/14</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0615 - 0630</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014 Q1 (January-March)</td>\n",
       "      <td>2013-14 Q4</td>\n",
       "      <td>CENCY001</td>\n",
       "      <td>Millbank (south of Thorney Street)</td>\n",
       "      <td>ven, 24/01/14</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0630 - 0645</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014 Q1 (January-March)</td>\n",
       "      <td>2013-14 Q4</td>\n",
       "      <td>CENCY001</td>\n",
       "      <td>Millbank (south of Thorney Street)</td>\n",
       "      <td>ven, 24/01/14</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0645 - 0700</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014 Q1 (January-March)</td>\n",
       "      <td>2013-14 Q4</td>\n",
       "      <td>CENCY001</td>\n",
       "      <td>Millbank (south of Thorney Street)</td>\n",
       "      <td>ven, 24/01/14</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0700 - 0715</td>\n",
       "      <td>AM peak (07:00-10:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Survey wave (calendar quarter) Equivalent financial quarter   Site ID  \\\n",
       "0        2014 Q1 (January-March)                   2013-14 Q4  CENCY001   \n",
       "1        2014 Q1 (January-March)                   2013-14 Q4  CENCY001   \n",
       "2        2014 Q1 (January-March)                   2013-14 Q4  CENCY001   \n",
       "3        2014 Q1 (January-March)                   2013-14 Q4  CENCY001   \n",
       "4        2014 Q1 (January-March)                   2013-14 Q4  CENCY001   \n",
       "\n",
       "                             Location    Survey date Weather         Time  \\\n",
       "0  Millbank (south of Thorney Street)  ven, 24/01/14     Dry  0600 - 0615   \n",
       "1  Millbank (south of Thorney Street)  ven, 24/01/14     Dry  0615 - 0630   \n",
       "2  Millbank (south of Thorney Street)  ven, 24/01/14     Dry  0630 - 0645   \n",
       "3  Millbank (south of Thorney Street)  ven, 24/01/14     Dry  0645 - 0700   \n",
       "4  Millbank (south of Thorney Street)  ven, 24/01/14     Dry  0700 - 0715   \n",
       "\n",
       "                        Period   Direction  Start hour  Start minute  \\\n",
       "0  Early Morning (06:00-07:00)  Northbound         6.0           0.0   \n",
       "1  Early Morning (06:00-07:00)  Northbound         6.0          15.0   \n",
       "2  Early Morning (06:00-07:00)  Northbound         6.0          30.0   \n",
       "3  Early Morning (06:00-07:00)  Northbound         6.0          45.0   \n",
       "4        AM peak (07:00-10:00)  Northbound         7.0           0.0   \n",
       "\n",
       "   Number of private cycles  Number of cycle hire bikes  Total cycles  \\\n",
       "0                       0.0                         0.0           0.0   \n",
       "1                      15.0                         0.0          15.0   \n",
       "2                      35.0                         0.0          35.0   \n",
       "3                      59.0                         2.0          61.0   \n",
       "4                      73.0                         0.0          73.0   \n",
       "\n",
       "   Unnamed: 14  Unnamed: 15  Unnamed: 16  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at samples of the data\n",
    "central_london.head(5)\n",
    "\n",
    "# Data similar in format to inner london but has some extra columns.\n",
    "# Will need to trim this Df to concatenate\n",
    "# Explore whether we need the extra columns here and if not will trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b8b881a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey wave (year)</th>\n",
       "      <th>Site ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Survey date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Time</th>\n",
       "      <th>Period</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Start hour</th>\n",
       "      <th>Start minute</th>\n",
       "      <th>Number of male cycles</th>\n",
       "      <th>Number of female cycles</th>\n",
       "      <th>Number of unknown cycles</th>\n",
       "      <th>Total cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>OUTCY001</td>\n",
       "      <td>High Road Leyton</td>\n",
       "      <td>ven, 26/06/15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0600 - 0615</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>OUTCY001</td>\n",
       "      <td>High Road Leyton</td>\n",
       "      <td>ven, 26/06/15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0615 - 0630</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>OUTCY001</td>\n",
       "      <td>High Road Leyton</td>\n",
       "      <td>ven, 26/06/15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0630 - 0645</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>OUTCY001</td>\n",
       "      <td>High Road Leyton</td>\n",
       "      <td>ven, 26/06/15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0645 - 0700</td>\n",
       "      <td>Early Morning (06:00-07:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>OUTCY001</td>\n",
       "      <td>High Road Leyton</td>\n",
       "      <td>ven, 26/06/15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0700 - 0715</td>\n",
       "      <td>AM peak (07:00-10:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survey wave (year)   Site ID          Location    Survey date Weather  \\\n",
       "0                2015  OUTCY001  High Road Leyton  ven, 26/06/15     Dry   \n",
       "1                2015  OUTCY001  High Road Leyton  ven, 26/06/15     Dry   \n",
       "2                2015  OUTCY001  High Road Leyton  ven, 26/06/15     Dry   \n",
       "3                2015  OUTCY001  High Road Leyton  ven, 26/06/15     Dry   \n",
       "4                2015  OUTCY001  High Road Leyton  ven, 26/06/15     Dry   \n",
       "\n",
       "          Time                       Period   Direction  Start hour  \\\n",
       "0  0600 - 0615  Early Morning (06:00-07:00)  Northbound           6   \n",
       "1  0615 - 0630  Early Morning (06:00-07:00)  Northbound           6   \n",
       "2  0630 - 0645  Early Morning (06:00-07:00)  Northbound           6   \n",
       "3  0645 - 0700  Early Morning (06:00-07:00)  Northbound           6   \n",
       "4  0700 - 0715        AM peak (07:00-10:00)  Northbound           7   \n",
       "\n",
       "   Start minute  Number of male cycles  Number of female cycles  \\\n",
       "0             0                      2                        1   \n",
       "1            15                      3                        0   \n",
       "2            30                      2                        0   \n",
       "3            45                      4                        0   \n",
       "4             0                      4                        1   \n",
       "\n",
       "   Number of unknown cycles  Total cycles  \n",
       "0                         0             3  \n",
       "1                         0             3  \n",
       "2                         0             2  \n",
       "3                         0             4  \n",
       "4                         0             5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at samples of the data\n",
    "outer_london.head(5)\n",
    "\n",
    "# Matches format of inner london."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2803d879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>TotalCount</th>\n",
       "      <th>ObjectId2</th>\n",
       "      <th>Time_0600</th>\n",
       "      <th>Time_0700</th>\n",
       "      <th>Time_0800</th>\n",
       "      <th>Time_1600</th>\n",
       "      <th>Time_1700</th>\n",
       "      <th>Time_1800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>March</td>\n",
       "      <td>2010</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>56</td>\n",
       "      <td>27</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>October</td>\n",
       "      <td>2015</td>\n",
       "      <td>383</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>69</td>\n",
       "      <td>100</td>\n",
       "      <td>47</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>March</td>\n",
       "      <td>2010</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>March</td>\n",
       "      <td>2010</td>\n",
       "      <td>333</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>15</td>\n",
       "      <td>62</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>October</td>\n",
       "      <td>2015</td>\n",
       "      <td>447</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>56</td>\n",
       "      <td>114</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SiteID    Month  Year  TotalCount  ObjectId2  Time_0600  Time_0700  \\\n",
       "0      51    March  2010         263          1         12         45   \n",
       "1       1  October  2015         383          2         37         69   \n",
       "2      52    March  2010         136          3          7         18   \n",
       "3      53    March  2010         333          4         25         86   \n",
       "4       2  October  2015         447          5         32         75   \n",
       "\n",
       "   Time_0800  Time_1600  Time_1700  Time_1800  \n",
       "0         56         27         56         67  \n",
       "1        100         47         68         62  \n",
       "2         31         29         30         21  \n",
       "3         93         15         62         52  \n",
       "4         72         56        114         98  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at samples of the data\n",
    "sydney_counts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f86accd",
   "metadata": {},
   "source": [
    "## Filter & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6949801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to remove space in column names\n",
    "inner_london.columns = inner_london.columns.str.replace(' ','_')\n",
    "central_london.columns = central_london.columns.str.replace(' ','_')\n",
    "outer_london.columns = outer_london.columns.str.replace(' ','_')\n",
    "sydney_counts.columns = sydney_counts.columns.str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d998e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove French Day name in Survey Date \n",
    "inner_london[\"Survey_date\"] = inner_london[\"Survey_date\"].str.replace(r'\\D+', '', regex=True)\n",
    "central_london[\"Survey_date\"] = central_london[\"Survey_date\"].str.replace(r'\\D+', '', regex=True)\n",
    "outer_london[\"Survey_date\"] = outer_london[\"Survey_date\"].str.replace(r'\\D+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "921e36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns\n",
    "ny_counts.dropna(how='all', axis=1, inplace=True)\n",
    "inner_london.dropna(how='all', axis=1, inplace=True)\n",
    "central_london.dropna(how='all', axis=1, inplace=True)\n",
    "outer_london.dropna(how='all', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0fae914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse London Df Dates into appropriate format\n",
    "# Convert to datetime format\n",
    "inner_london['Survey_date'] = pd.to_datetime(inner_london.Survey_date)\n",
    "central_london['Survey_date'] = pd.to_datetime(central_london.Survey_date)\n",
    "outer_london['Survey_date'] = pd.to_datetime(outer_london.Survey_date)\n",
    "\n",
    "# Sort DataFrame by chronological order\n",
    "inner_london = inner_london.sort_values(['Survey_date', 'Start_hour', 'Start_minute'])\n",
    "central_london = central_london.sort_values(['Survey_date', 'Start_hour', 'Start_minute'])\n",
    "outer_london = outer_london.sort_values(['Survey_date', 'Start_hour', 'Start_minute'])\n",
    "\n",
    "# Replace with value of previous value row where there is a missing value in Survey_date\n",
    "inner_london['Survey_date'].fillna(method='ffill', inplace=True)\n",
    "central_london['Survey_date'].fillna(method='ffill', inplace=True)\n",
    "outer_london['Survey_date'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Define day of the week in English and add back as a column\n",
    "inner_london['Day_of_week'] = inner_london['Survey_date'].dt.day_name()\n",
    "central_london['Day_of_week'] = central_london['Survey_date'].dt.day_name()\n",
    "outer_london['Day_of_week'] = outer_london['Survey_date'].dt.day_name()\n",
    "\n",
    "# Pass Month into a new column\n",
    "inner_london['month'] = inner_london['Survey_date'].dt.month\n",
    "central_london['month'] = central_london['Survey_date'].dt.month\n",
    "outer_london['month'] = outer_london['Survey_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7183ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass Season\n",
    "# Create function for user defined seasons\n",
    "def f(x):\n",
    "    if (x >= 1) and (x <= 2):\n",
    "        return 'Winter'\n",
    "    elif (x > 2) and (x <= 5 ):\n",
    "        return 'Spring'\n",
    "    elif (x > 5) and (x <= 8):\n",
    "        return'Summer'\n",
    "    elif (x > 8) and (x <= 11) :\n",
    "        return 'Autumn'\n",
    "    elif (x > 11):\n",
    "        return'Winter'\n",
    "\n",
    "# Apply user defined function to create new column with seasons\n",
    "inner_london['season'] = inner_london['month'].apply(f)\n",
    "central_london['season'] = central_london['month'].apply(f)\n",
    "outer_london['season'] = outer_london['month'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2ceca72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>counts</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2059019</th>\n",
       "      <td>100047029</td>\n",
       "      <td>2012-08-31 00:00:00</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205445</th>\n",
       "      <td>100062893</td>\n",
       "      <td>2012-08-31 00:00:00</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164087</th>\n",
       "      <td>100005020</td>\n",
       "      <td>2012-08-31 00:00:00</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370586</th>\n",
       "      <td>100051865</td>\n",
       "      <td>2012-08-31 00:00:00</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165734</th>\n",
       "      <td>100005020</td>\n",
       "      <td>2012-08-31 00:15:00</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16707</th>\n",
       "      <td>100062893</td>\n",
       "      <td>2022-07-04 23:45:00</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16803</th>\n",
       "      <td>300020241</td>\n",
       "      <td>2022-07-04 23:45:00</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>300024007</td>\n",
       "      <td>2022-07-04 23:45:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16323</th>\n",
       "      <td>100047029</td>\n",
       "      <td>2022-07-04 23:45:00</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16227</th>\n",
       "      <td>100010022</td>\n",
       "      <td>2022-07-04 23:45:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4167507 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                date  counts  status\n",
       "2059019  100047029 2012-08-31 00:00:00      41       4\n",
       "3205445  100062893 2012-08-31 00:00:00      41       4\n",
       "4164087  100005020 2012-08-31 00:00:00      41       4\n",
       "2370586  100051865 2012-08-31 00:00:00      41       4\n",
       "4165734  100005020 2012-08-31 00:15:00      52       4\n",
       "...            ...                 ...     ...     ...\n",
       "16707    100062893 2022-07-04 23:45:00      34       0\n",
       "16803    300020241 2022-07-04 23:45:00      16       0\n",
       "16995    300024007 2022-07-04 23:45:00       2       0\n",
       "16323    100047029 2022-07-04 23:45:00      34       0\n",
       "16227    100010022 2022-07-04 23:45:00       1       0\n",
       "\n",
       "[4167507 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup NY Dates\n",
    "# Make sure that the data is sorted in cbronological order without altering anything else for the moment\n",
    "ny_counts.sort_values(by='date')\n",
    "# Can see data set runs from 31 Aug 2012 to 04 Jul 2022\n",
    "# Can extract hour of the day to look for patterns. Expect peak vs off peak patterns\n",
    "# We can also group the data by day of the week to look for patterns within that\n",
    "# We can also see that its possible to group the data into month to look for seasonal patterns\n",
    "# We can also group/subset the data by id which is another spatial/location identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5483ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year information from timestamped date column\n",
    "ny_counts['year'] = ny_counts['date'].dt.year\n",
    "\n",
    "# Extract hour information first from timestamped date column\n",
    "ny_counts['hour'] = ny_counts['date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bee88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user defined function for peak and off peak hours to match London Data\n",
    "def f(x):\n",
    "    if (x > 6) and (x <= 7):\n",
    "        return 'Early Morning'\n",
    "    elif (x > 7) and (x <= 10 ):\n",
    "        return 'AM peak'\n",
    "    elif (x > 10) and (x <= 16):\n",
    "        return'Inter Peak'\n",
    "    elif (x > 16) and (x <= 19) :\n",
    "        return 'PM Peak'\n",
    "    elif (x > 19) and (x <= 23):\n",
    "        return'Evening'\n",
    "    elif (x <= 6):\n",
    "        return'Night'\n",
    "    \n",
    "# Apply user defined function to create new column with peak and off peak hours\n",
    "ny_counts['time_of_day'] = ny_counts['hour'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f14f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define day of the week and add as column to match London Data\n",
    "ny_counts = ny_counts.assign(day_of_week = lambda x: x.date.dt.day_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c3ad2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define month to calculate user defined seasons to match London\n",
    "# Extract month information first from timestamped date column\n",
    "ny_counts['month'] = ny_counts['date'].dt.month\n",
    "\n",
    "# Create user defined function for seasons\n",
    "def f(x):\n",
    "    if (x >= 1) and (x <= 2):\n",
    "        return 'Winter'\n",
    "    elif (x > 2) and (x <= 5 ):\n",
    "        return 'Spring'\n",
    "    elif (x > 5) and (x <= 8):\n",
    "        return'Summer'\n",
    "    elif (x > 8) and (x <= 11) :\n",
    "        return 'Autumn'\n",
    "    elif (x > 11):\n",
    "        return'Winter'\n",
    "\n",
    "# Apply user defined function to create new column with seasons\n",
    "ny_counts['season'] = ny_counts['month'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c48c6fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the order of the columns so they flow more logically within the DataFrame\n",
    "neworder = ['id', 'date', 'day_of_week', 'month', 'season', 'year', 'hour', 'time_of_day', 'counts', 'status']\n",
    "ny_counts = ny_counts.reindex(columns=neworder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a9c1c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4]\n"
     ]
    }
   ],
   "source": [
    "# Investigate in Ny_counts what status there is\n",
    "print(ny_counts.status.unique())\n",
    "\n",
    "# As both status as within acceptable boundaries can drop status column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0b29a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns\n",
    "ny_counts=ny_counts.drop(['status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e63bf8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>TotalCount</th>\n",
       "      <th>ObjectId2</th>\n",
       "      <th>Early_Morning</th>\n",
       "      <th>AM_Peak1</th>\n",
       "      <th>AM_Peak2</th>\n",
       "      <th>PM_Peak1</th>\n",
       "      <th>PM_Peak2</th>\n",
       "      <th>PM_Peak3</th>\n",
       "      <th>AM_Peak</th>\n",
       "      <th>PM_Peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>57</td>\n",
       "      <td>October</td>\n",
       "      <td>2016</td>\n",
       "      <td>78</td>\n",
       "      <td>1773</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>55</td>\n",
       "      <td>March</td>\n",
       "      <td>2021</td>\n",
       "      <td>247</td>\n",
       "      <td>1963</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>84</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>100</td>\n",
       "      <td>March</td>\n",
       "      <td>2019</td>\n",
       "      <td>378</td>\n",
       "      <td>838</td>\n",
       "      <td>41</td>\n",
       "      <td>55</td>\n",
       "      <td>82</td>\n",
       "      <td>48</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>137</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>19</td>\n",
       "      <td>October</td>\n",
       "      <td>2017</td>\n",
       "      <td>303</td>\n",
       "      <td>2118</td>\n",
       "      <td>27</td>\n",
       "      <td>71</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>164</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>65</td>\n",
       "      <td>March</td>\n",
       "      <td>2014</td>\n",
       "      <td>1528</td>\n",
       "      <td>1329</td>\n",
       "      <td>136</td>\n",
       "      <td>318</td>\n",
       "      <td>363</td>\n",
       "      <td>144</td>\n",
       "      <td>288</td>\n",
       "      <td>279</td>\n",
       "      <td>681</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SiteID    Month  Year  TotalCount  ObjectId2  Early_Morning  AM_Peak1  \\\n",
       "1716      57  October  2016          78       1773              9         6   \n",
       "1885      55    March  2021         247       1963             15        40   \n",
       "837      100    March  2019         378        838             41        55   \n",
       "2040      19  October  2017         303       2118             27        71   \n",
       "1328      65    March  2014        1528       1329            136       318   \n",
       "\n",
       "      AM_Peak2  PM_Peak1  PM_Peak2  PM_Peak3  AM_Peak  PM_Peak  \n",
       "1716        15         9        19        20       21       48  \n",
       "1885        44        41        63        44       84      148  \n",
       "837         82        48        74        78      137      200  \n",
       "2040        93        20        43        49      164      112  \n",
       "1328       363       144       288       279      681      711  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the Sydney columns to align to Peak/off Peak of other Df.\n",
    "sydney_counts.rename(columns = {\"Time_0600\":\"Early_Morning\",\n",
    "                              \"Time_0700\":\"AM_Peak1\",\n",
    "                              \"Time_0800\":\"AM_Peak2\",\n",
    "                              \"Time_1600\":\"PM_Peak1\",\n",
    "                              \"Time_1700\":\"PM_Peak2\",\n",
    "                              \"Time_1800\":\"PM_Peak3\"},\n",
    "                             inplace=True)\n",
    "\n",
    "# Add All AM Peak and PM Peak Columns into 2 columns only to align to the way other Dfs are presented\n",
    "sydney_counts['AM_Peak'] = sydney_counts['AM_Peak1'] + sydney_counts['AM_Peak2'] \n",
    "sydney_counts['PM_Peak'] = sydney_counts['PM_Peak1'] + sydney_counts['PM_Peak2'] + sydney_counts['PM_Peak3']\n",
    "\n",
    "# View Output with 5 random samples \n",
    "sydney_counts.sample(5)\n",
    "\n",
    "# Can consolidate some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17287313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where total cycles doesnt add up to number of private and hire cycles.\n",
    "# Creating a column to add up the values\n",
    "sydney_counts['Sum'] = sydney_counts['AM_Peak'] + sydney_counts['PM_Peak'] + sydney_counts['Early_Morning']\n",
    "\n",
    "# Dropping rows where the column values dont add up \n",
    "sydney_counts = sydney_counts[sydney_counts.TotalCount == sydney_counts.Sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4cf0add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2186 entries, 0 to 2214\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   SiteID         2186 non-null   int64 \n",
      " 1   Month          2186 non-null   object\n",
      " 2   Year           2186 non-null   int64 \n",
      " 3   TotalCount     2186 non-null   int64 \n",
      " 4   ObjectId2      2186 non-null   int64 \n",
      " 5   Early_Morning  2186 non-null   int64 \n",
      " 6   AM_Peak1       2186 non-null   int64 \n",
      " 7   AM_Peak2       2186 non-null   int64 \n",
      " 8   PM_Peak1       2186 non-null   int64 \n",
      " 9   PM_Peak2       2186 non-null   int64 \n",
      " 10  PM_Peak3       2186 non-null   int64 \n",
      " 11  AM_Peak        2186 non-null   int64 \n",
      " 12  PM_Peak        2186 non-null   int64 \n",
      " 13  Sum            2186 non-null   int64 \n",
      "dtypes: int64(13), object(1)\n",
      "memory usage: 256.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sydney_counts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59c1fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns\n",
    "sydney_counts=sydney_counts.drop(['ObjectId2', 'AM_Peak1', 'AM_Peak2', 'PM_Peak1', 'PM_Peak2', 'PM_Peak3', 'Sum'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "754ce8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where total cycles doesnt add up to number of private and hire cycles.\n",
    "# Creating a column to add up the values\n",
    "inner_london['Sum'] = inner_london['Number_of_private_cycles'] + inner_london['Number_of_cycle_hire_bikes']\n",
    "\n",
    "# Dropping rows where the column values dont add up \n",
    "inner_london = inner_london[inner_london.Total_cycles == inner_london.Sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3fb5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where total cycles doesnt add up to number of private and hire cycles.\n",
    "# Creating a column to add up the values\n",
    "central_london['Sum'] = central_london['Number_of_private_cycles'] + central_london['Number_of_cycle_hire_bikes']\n",
    "\n",
    "# Dropping rows where the column values dont add up \n",
    "central_london = central_london[central_london.Total_cycles == central_london.Sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "127c5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where total cycles doesnt add up to number of private and hire cycles.\n",
    "# Creating a column to add up the values\n",
    "outer_london['Sum'] = outer_london['Number_of_male_cycles'] + outer_london['Number_of_female_cycles'] + outer_london['Number_of_unknown_cycles']\n",
    "\n",
    "# Dropping rows where the column values dont add up \n",
    "outer_london = outer_london[outer_london.Total_cycles == outer_london.Sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "264bb21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey_wave_(year)</th>\n",
       "      <th>Site_ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Survey_date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Time</th>\n",
       "      <th>Period</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Start_hour</th>\n",
       "      <th>Start_minute</th>\n",
       "      <th>Number_of_private_cycles</th>\n",
       "      <th>Number_of_cycle_hire_bikes</th>\n",
       "      <th>Total_cycles</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201273</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>INNCY379</td>\n",
       "      <td>Acacia Road</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>Dry</td>\n",
       "      <td>2015 - 2030</td>\n",
       "      <td>Evening (19:00-22:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>5</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320209</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>INNCY114</td>\n",
       "      <td>Cromwell Road</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1015 - 1030</td>\n",
       "      <td>Inter-peak (10:00-16:00)</td>\n",
       "      <td>Westbound</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151602</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>INNCY588</td>\n",
       "      <td>Tooting Bec Common</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1830 - 1845</td>\n",
       "      <td>PM peak (16:00-19:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261986</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>INNCY256</td>\n",
       "      <td>Lowndes Street</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1430 - 1445</td>\n",
       "      <td>Inter-peak (10:00-16:00)</td>\n",
       "      <td>Southbound</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>6</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218485</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>INNCY513</td>\n",
       "      <td>Tangley Grove</td>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1915 - 1930</td>\n",
       "      <td>Evening (19:00-22:00)</td>\n",
       "      <td>Southbound</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survey_wave_(year)   Site_ID            Location Survey_date Weather  \\\n",
       "201273              2017.0  INNCY379         Acacia Road  2017-05-07     Dry   \n",
       "320209              2019.0  INNCY114       Cromwell Road  2019-07-15     Dry   \n",
       "151602              2016.0  INNCY588  Tooting Bec Common  2016-04-19     Dry   \n",
       "261986              2018.0  INNCY256      Lowndes Street  2018-06-22     Dry   \n",
       "218485              2017.0  INNCY513       Tangley Grove  2017-05-17     Dry   \n",
       "\n",
       "               Time                    Period   Direction  Start_hour  \\\n",
       "201273  2015 - 2030     Evening (19:00-22:00)  Northbound        20.0   \n",
       "320209  1015 - 1030  Inter-peak (10:00-16:00)   Westbound        10.0   \n",
       "151602  1830 - 1845     PM peak (16:00-19:00)  Northbound        18.0   \n",
       "261986  1430 - 1445  Inter-peak (10:00-16:00)  Southbound        14.0   \n",
       "218485  1915 - 1930     Evening (19:00-22:00)  Southbound        19.0   \n",
       "\n",
       "        Start_minute  Number_of_private_cycles  Number_of_cycle_hire_bikes  \\\n",
       "201273          15.0                       0.0                         0.0   \n",
       "320209          15.0                       0.0                         0.0   \n",
       "151602          30.0                       2.0                         0.0   \n",
       "261986          30.0                       0.0                         0.0   \n",
       "218485          15.0                       0.0                         0.0   \n",
       "\n",
       "        Total_cycles Day_of_week  month  season  Sum  \n",
       "201273           0.0      Sunday      5  Spring  0.0  \n",
       "320209           0.0      Monday      7  Summer  0.0  \n",
       "151602           2.0     Tuesday      4  Spring  2.0  \n",
       "261986           0.0      Friday      6  Summer  0.0  \n",
       "218485           0.0   Wednesday      5  Spring  0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all other dataframes to quickly review their structure before merging\n",
    "inner_london.sample(5)\n",
    "\n",
    "# Can consolidate Columns\n",
    "# Need to remove formatting for survey_wave_(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61f7493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the decimal point in Survey_wave\n",
    "inner_london['Survey_wave_(year)'] = inner_london['Survey_wave_(year)'].astype(str).apply(lambda x: x.replace('.0','')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bb60e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns\n",
    "inner_london=inner_london.drop(['Sum', 'Start_hour', 'Start_minute'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b45f30a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey_wave_(calendar_quarter)</th>\n",
       "      <th>Equivalent_financial_quarter</th>\n",
       "      <th>Site_ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Survey_date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Time</th>\n",
       "      <th>Period</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Start_hour</th>\n",
       "      <th>Start_minute</th>\n",
       "      <th>Number_of_private_cycles</th>\n",
       "      <th>Number_of_cycle_hire_bikes</th>\n",
       "      <th>Total_cycles</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23911</th>\n",
       "      <td>2014 Q1 (January-March)</td>\n",
       "      <td>2013-14 Q4</td>\n",
       "      <td>CENCY190</td>\n",
       "      <td>Hastings Street</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>Wet</td>\n",
       "      <td>1545 - 1600</td>\n",
       "      <td>Inter-peak (10:00-16:00)</td>\n",
       "      <td>Westbound</td>\n",
       "      <td>15.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87238</th>\n",
       "      <td>2014 Q4 (October-December)</td>\n",
       "      <td>2014-15 Q3</td>\n",
       "      <td>CENCY083</td>\n",
       "      <td>Borough High Street</td>\n",
       "      <td>2014-10-11</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0730 - 0745</td>\n",
       "      <td>AM peak (07:00-10:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>10</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476653</th>\n",
       "      <td>2018 Q3 (July-September)</td>\n",
       "      <td>2018-19 Q2</td>\n",
       "      <td>CENCY087</td>\n",
       "      <td>Lower Thames Street</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1715 - 1730</td>\n",
       "      <td>PM peak (16:00-19:00)</td>\n",
       "      <td>Eastbound</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>7</td>\n",
       "      <td>Summer</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482198</th>\n",
       "      <td>2018 Q3 (July-September)</td>\n",
       "      <td>2018-19 Q2</td>\n",
       "      <td>CENCY130</td>\n",
       "      <td>Gresham Street</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1130 - 1145</td>\n",
       "      <td>Inter-peak (10:00-16:00)</td>\n",
       "      <td>Westbound</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>9</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663948</th>\n",
       "      <td>2020 Q3 (July-September)</td>\n",
       "      <td>2020-21 Q2</td>\n",
       "      <td>CENCY082</td>\n",
       "      <td>Long Lane</td>\n",
       "      <td>2020-09-15</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0900 - 0915</td>\n",
       "      <td>AM peak (07:00-10:00)</td>\n",
       "      <td>Westbound</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>9</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Survey_wave_(calendar_quarter) Equivalent_financial_quarter   Site_ID  \\\n",
       "23911         2014 Q1 (January-March)                   2013-14 Q4  CENCY190   \n",
       "87238      2014 Q4 (October-December)                   2014-15 Q3  CENCY083   \n",
       "476653       2018 Q3 (July-September)                   2018-19 Q2  CENCY087   \n",
       "482198       2018 Q3 (July-September)                   2018-19 Q2  CENCY130   \n",
       "663948       2020 Q3 (July-September)                   2020-21 Q2  CENCY082   \n",
       "\n",
       "                   Location Survey_date Weather         Time  \\\n",
       "23911       Hastings Street  2014-01-29     Wet  1545 - 1600   \n",
       "87238   Borough High Street  2014-10-11     Dry  0730 - 0745   \n",
       "476653  Lower Thames Street  2018-07-17     Dry  1715 - 1730   \n",
       "482198       Gresham Street  2018-09-25     Dry  1130 - 1145   \n",
       "663948            Long Lane  2020-09-15     Dry  0900 - 0915   \n",
       "\n",
       "                          Period   Direction  Start_hour  Start_minute  \\\n",
       "23911   Inter-peak (10:00-16:00)   Westbound        15.0          45.0   \n",
       "87238      AM peak (07:00-10:00)  Northbound         7.0          30.0   \n",
       "476653     PM peak (16:00-19:00)   Eastbound        17.0          15.0   \n",
       "482198  Inter-peak (10:00-16:00)   Westbound        11.0          30.0   \n",
       "663948     AM peak (07:00-10:00)   Westbound         9.0           0.0   \n",
       "\n",
       "        Number_of_private_cycles  Number_of_cycle_hire_bikes  Total_cycles  \\\n",
       "23911                        1.0                         0.0           1.0   \n",
       "87238                      109.0                         2.0         111.0   \n",
       "476653                     134.0                        19.0         153.0   \n",
       "482198                      11.0                         2.0          13.0   \n",
       "663948                       9.0                         3.0          12.0   \n",
       "\n",
       "       Day_of_week  month  season    Sum  \n",
       "23911    Wednesday      1  Winter    1.0  \n",
       "87238     Saturday     10  Autumn  111.0  \n",
       "476653     Tuesday      7  Summer  153.0  \n",
       "482198     Tuesday      9  Autumn   13.0  \n",
       "663948     Tuesday      9  Autumn   12.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all other dataframes to quickly review their structure before merging\n",
    "central_london.sample(5)\n",
    "\n",
    "# Can consolidate/drop some Columns\n",
    "# Need to remove formatting for survey_wave_(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce08a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the additional information in Survey wave column \n",
    "# alligns with the way this info is presented in the other London datasets.\n",
    "central_london[\"Survey_wave_(calendar_quarter)\"] = central_london[\"Survey_wave_(calendar_quarter)\"].str.replace(r'\\D+', '', regex=True)\n",
    "\n",
    "# Drop the last number in every row \n",
    "central_london['Survey_wave_(calendar_quarter)'] = central_london['Survey_wave_(calendar_quarter)'].astype(str).str[:-1].astype(np.int64)\n",
    "\n",
    "# Rename Column Name to align with other London Datasets\n",
    "central_london.rename(columns={'Survey_wave_(calendar_quarter)': 'Survey_wave_(year)'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f58623e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns\n",
    "central_london=central_london.drop(['Sum', 'Start_hour', 'Start_minute', 'Equivalent_financial_quarter'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a972ca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey_wave_(year)</th>\n",
       "      <th>Site_ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Survey_date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Time</th>\n",
       "      <th>Period</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Start_hour</th>\n",
       "      <th>Start_minute</th>\n",
       "      <th>Number_of_male_cycles</th>\n",
       "      <th>Number_of_female_cycles</th>\n",
       "      <th>Number_of_unknown_cycles</th>\n",
       "      <th>Total_cycles</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146491</th>\n",
       "      <td>2017</td>\n",
       "      <td>OUTCY243</td>\n",
       "      <td>Elmfield Avenue</td>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>Dry</td>\n",
       "      <td>2045 - 2100</td>\n",
       "      <td>Evening (19:00-22:00)</td>\n",
       "      <td>Northbound</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>6</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73336</th>\n",
       "      <td>2016</td>\n",
       "      <td>OUTCY122</td>\n",
       "      <td>Wickham Road</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>Wet</td>\n",
       "      <td>2000 - 2015</td>\n",
       "      <td>Evening (19:00-22:00)</td>\n",
       "      <td>Southbound</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115441</th>\n",
       "      <td>2016</td>\n",
       "      <td>OUTCY451</td>\n",
       "      <td>Thames Path (Lower Ham Road)</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>Wet</td>\n",
       "      <td>1815 - 1830</td>\n",
       "      <td>PM peak (16:00-19:00)</td>\n",
       "      <td>Southbound</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Monday</td>\n",
       "      <td>9</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219654</th>\n",
       "      <td>2018</td>\n",
       "      <td>OUTCY364</td>\n",
       "      <td>Gorringe Park Avenue</td>\n",
       "      <td>2018-07-19</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0730 - 0745</td>\n",
       "      <td>AM peak (07:00-10:00)</td>\n",
       "      <td>Eastbound</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>7</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57413</th>\n",
       "      <td>2015</td>\n",
       "      <td>OUTCY449</td>\n",
       "      <td>Glen Walk</td>\n",
       "      <td>2015-03-06</td>\n",
       "      <td>Dry</td>\n",
       "      <td>0715 - 0730</td>\n",
       "      <td>AM peak (07:00-10:00)</td>\n",
       "      <td>Southbound</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3</td>\n",
       "      <td>Spring</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survey_wave_(year)   Site_ID                      Location  \\\n",
       "146491                2017  OUTCY243               Elmfield Avenue   \n",
       "73336                 2016  OUTCY122                  Wickham Road   \n",
       "115441                2016  OUTCY451  Thames Path (Lower Ham Road)   \n",
       "219654                2018  OUTCY364          Gorringe Park Avenue   \n",
       "57413                 2015  OUTCY449                     Glen Walk   \n",
       "\n",
       "       Survey_date Weather         Time                 Period   Direction  \\\n",
       "146491  2017-06-20     Dry  2045 - 2100  Evening (19:00-22:00)  Northbound   \n",
       "73336   2016-04-27     Wet  2000 - 2015  Evening (19:00-22:00)  Southbound   \n",
       "115441  2016-09-05     Wet  1815 - 1830  PM peak (16:00-19:00)  Southbound   \n",
       "219654  2018-07-19     Dry  0730 - 0745  AM peak (07:00-10:00)   Eastbound   \n",
       "57413   2015-03-06     Dry  0715 - 0730  AM peak (07:00-10:00)  Southbound   \n",
       "\n",
       "        Start_hour  Start_minute  Number_of_male_cycles  \\\n",
       "146491          20            45                      0   \n",
       "73336           20             0                      0   \n",
       "115441          18            15                      3   \n",
       "219654           7            30                      0   \n",
       "57413            7            15                      6   \n",
       "\n",
       "        Number_of_female_cycles  Number_of_unknown_cycles  Total_cycles  \\\n",
       "146491                        0                         0             0   \n",
       "73336                         0                         0             0   \n",
       "115441                        0                         0             3   \n",
       "219654                        0                         0             0   \n",
       "57413                         0                         0             6   \n",
       "\n",
       "       Day_of_week  month  season  Sum  \n",
       "146491     Tuesday      6  Summer    0  \n",
       "73336    Wednesday      4  Spring    0  \n",
       "115441      Monday      9  Autumn    3  \n",
       "219654    Thursday      7  Summer    0  \n",
       "57413       Friday      3  Spring    6  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all other dataframes to quickly review their structure before merging\n",
    "outer_london.sample(5)\n",
    "\n",
    "# Can consolidate Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff224022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns\n",
    "outer_london=outer_london.drop(['Sum', 'Start_hour', 'Start_minute'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da84da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey_wave_(year) :  7\n",
      "Site_ID :  597\n",
      "Location :  584\n",
      "Survey_date :  463\n",
      "Weather :  165\n",
      "Time :  64\n",
      "Period :  5\n",
      "Direction :  4\n",
      "Number_of_private_cycles :  221\n",
      "Number_of_cycle_hire_bikes :  28\n",
      "Total_cycles :  233\n",
      "Day_of_week :  7\n",
      "month :  12\n",
      "season :  4\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in each column\n",
    "for col in inner_london:\n",
    "  print(col,\": \", inner_london[col].nunique())\n",
    "\n",
    "# More site ids vs location\n",
    "# May imply multiple sites in same location. Does this double count? Need to check!\n",
    "# Survey period of over 7 years\n",
    "# 5 Periods of day which should be synched in same fashion with all the other city count data\n",
    "# will use london period of day definition as base.\n",
    "# 165 types of weather needs to be consolidated into more manageable fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46795a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dry' 'Windy/rain' nan 'Wet' 'Rain' 'Drizzle' 'Sunny' 'Overcast' 'Cloudy'\n",
      " 'Fine' 'Cloudy/sunny' 'Dry Wet Road' 'Cloudy/rain' 'Cloudy/dry'\n",
      " 'Dry & Windy' 'Mizzle' 'High Wind' 'Dry/sunny' 'Dry/sun' 'S.wet' 'S/w'\n",
      " 'Sun' 'Wet/damp' 'Shower' 'Druy' 'Mix Wet/dry' 'Wet/dry' 'Very Windy'\n",
      " 'Dry                         9' 'Dry/hot' 'Dark/cloudy' 'Dry/overcast'\n",
      " 'Warm + Dry' 'Dry Warm' 'Light Showers' 'Showers' 'Light Rain' 'Spitting'\n",
      " 'Wet (shower)' 'Down Pour' 'Heavy Rain' 'Shower/dry' 'Hail Stone' 'Sleet'\n",
      " 'Snow' 'Damp' 'Thunder' 'Fair' 'Rain/sleet' 'Too Cold' 'Dry Cold' 'Hot'\n",
      " 'Dull' 'Sun/cloudy' 'Wet/mix' 'Heavy Thunder' 'Drizzle/cloudy' 'Dry/wet'\n",
      " 'Overcast/rain Heavy Showers' 'Overcast/dry' 'Bright/dry' 'Cloud'\n",
      " 'Dull/damp' 'Dry/drizzle' 'Dry-wet' 'Dry Sunny' 'Rain Shower' 'Dry/cold'\n",
      " 'Hail' 'Wet Road' 'Drizzle/dry' 'Drizzle/rain' 'Intermittent Showers'\n",
      " 'Dry/v. Windy' 'Dry Windy' 'Windy' 'N/a' 'V Light Drizzle' 'D' 'W'\n",
      " 'Drizzle/wet' 'Rainy' 'Warm/dry' 'Wet/windy' 'Heavy Rain High Winds'\n",
      " 'V Wet' 'Sunny (hot!)' 'Dry/cloudy' 'Cloudy/drizzle' 'Rain/drizzle'\n",
      " 'Mixed Sunny + Rain' 'Cloudy/sun' 'Cloudy Sun' 'Wet/rain' 'Rain Heavy'\n",
      " 'Dry Road Still Wet' 'Sunny/cloudy' 'Stopped Raining' 'Showery'\n",
      " 'Overcast/rain' 'Rain Stopped' 'Slight Drizzle/dry' 'Slight Drizzle'\n",
      " 'Rain/wet' 'Drizzle Rain' 'Rain/showers' 'Showers/sunny'\n",
      " 'Drizzle/showers' 'Cloudy Dry' 'Wet/stop Raining' 'Drizzle Wet' 'Dry Y'\n",
      " 'Dr Ry' 'Sun/cloud' 'School Out' 'Clear' 'Mixed' 'Storm' 'Sunny/dry'\n",
      " 'Dry + Sunny' 'Very Hot/dry' 'Hot/dry' 'Raining/wet' 'Wet Rain Stopped'\n",
      " 'Cloud/sun' 'Cold' 'Sun/clouds' 'Cloudy & Sunny' 'Showers/cloudy'\n",
      " 'Sun & Clouds' 'Bright' 'Windy At First Then Sunny'\n",
      " 'Sunny & Warm All Day' 'Dry + Wet' 'Getting Wet' 'Cloudy/showers'\n",
      " 'Clouds & Sunny' 'Drizze' 'Heavy Showers' 'Damp/sun' 'Showers/hailstone'\n",
      " 'Rain/hailstone' 'Wet Road:sun' 'Intermittent Heavy Showers' 'Raining'\n",
      " 'Very Heavy Rain' 'Dry But Misty' 'Dry But Wet Road'\n",
      " 'Partly cloudy and dry' 'Windy Dry' 'Sun/Cloudy' 'wet'\n",
      " 'Cloudy with Clear Intervals' 'Clear and Warm' 'Dryish' 'Wettish'\n",
      " 'Clear and Dry' 'Clear And Dry' 'Cloudy and Dry' 'Unknown'\n",
      " 'Partly cloudy but dry' 'Partly cloudy and Dry' 'Dry, Sunny, Hot'\n",
      " 'Dry, Warm' 'Dry, Sunny, Warm' 'Cloudy but dry']\n"
     ]
    }
   ],
   "source": [
    "# Explore the different types of Weather\n",
    "print(inner_london.Weather.unique())\n",
    "\n",
    "# Lots of overlaps for e.g. Rain & Wet, Dry/cold and dry Cold.\n",
    "# Need to classify into much narrower streams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb276734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate descriptions in Weather\n",
    "# Rain\n",
    "inner_london['Weather'] = inner_london['Weather'].replace(['Wet','Cloudy/rain','Rain','Mix Wet/dry','Drizzle',\n",
    "                                                          'Light Showers', 'Mizzle','Windy/rain','Showers',\n",
    "                                                          'Wet/dry','Wet/damp','Shower','Drizzle/shower','Rainy',\n",
    "                                                          'wet','Cloudy with showers','Generally overcast brief shower'\n",
    "                                                          'Light Rain','Shower/dry','Spitting','Drizzle/cloudy',\n",
    "                                                          'Dry/wet','Damp', 'Dry/drizzle','Dull/damp','Dry-wet',\n",
    "                                                          'Wet/mix', 'Drizzle/wet','Wet/windy','Rain Shower',\n",
    "                                                          'Intermittent Showers','Cloudy/drizzle','Rain/drizzle',\n",
    "                                                          'Wet Road','Drizzle/dry','Drizzle/rain','Mixed Sunny + Rain',\n",
    "                                                          'Wet/rain', 'V Light Drizzle', 'Rainy', 'W','Slight Drizzle',\n",
    "                                                          'Rain Stopped', 'Stopped Raining','Wet Rain Stopped','Raining/wet',\n",
    "                                                          'Showery','Overcast/rain','Rain/wet','Rain/showers','Showers/sunny',\n",
    "                                                          'Drizzle/showers','Wet/stop Raining','Drizzle Rain','Drizzle Wet',\n",
    "                                                          'Damp/sun','Raining','Dry + Wet','Showers/cloudy','Cloudy/showers',\n",
    "                                                          'Getting Wet','Wet Road:sun','Dry But Wet Road','Drizze',\n",
    "                                                          'wet','Wettish','Light Rain','S.wet','S/w',\n",
    "                                                          'Heavy Rain','Heavy Shower','Heavy Shr','Down Pour',\n",
    "                                                           'Deluge','Heavy Showers', 'Shower','Rain Heavy Showers',\n",
    "                                                           'Intermitent Showers','Thunder Lightening Rain!','Very Wet',\n",
    "                                                           'V.wet','Heavy Downpour/rain','Showery','Wet Heavy Rain',\n",
    "                                                           'Wet (heavy Rain)','Wet (shower)'],'Rain')\n",
    "\n",
    "# Good\n",
    "inner_london['Weather'] = inner_london['Weather'].replace(['Sunny','Cloudy Sunny','Sun Setting','Good','Dry/sunny',\n",
    "                                                          'Fine + Dry', 'Fine + Hot','Bright','Dry Hot!!',\n",
    "                                                          'Dry & Sunny','Dry & Sun','Fine & Dry','Good/dry','Sun',\n",
    "                                                          'Sunny Dry','Clear and Bright', 'Fine', 'Dry/good', \n",
    "                                                          'Fine/dry', 'Warm + Dry','Dry','Dry                         9',\n",
    "                                                          'Sunny','Cloudy/sunny','Druy','Dry/hot','Dry Warm',\n",
    "                                                          'Dry/sun','Dryish','Clear And Dry','Clear and Dry','Dry, Warm',\n",
    "                                                          'Dry, Sunny, Warm','Cloudy with Clear Intervals','Clear and Warm',\n",
    "                                                          'Dry But Misty','Sunny & Warm All Day','Clear','Dry + Sunny',\n",
    "                                                          'Sunny/dry','Dr Ry','Dry Y','D','Warm/dry','Bright/dry','Dry Sunny',\n",
    "                                                          'Fair','Dry/sun','Cloudy','Sunny Overcast Sunny','Sunny/cloudy','Cloudy/rain/sunny',\n",
    "                                                           'Cloudy + Sunny','Sunny + Cloudy', 'Cloudy/sunny',\n",
    "                                                           'Bright + Cloudy','Cloudy/dry','Partly Sunny','Dull','Dry & Mild',\n",
    "                                                           'Cloud','Overcast','Mild','Overcast (No Rain)',\n",
    "                                                          'Cloudy bright intervals','Generally overcast',\n",
    "                                                           'Cloudy with clear spells','Sunny Overcast','Dry',\n",
    "                                                           'Dry/mild', 'Clear','Cloudy and Dry','Partly cloudy but dry',\n",
    "                                                          'Partly cloudy and dry','Cloudy but dry','Partly cloudy and Dry',\n",
    "                                                          'Sun/Cloudy','Clouds & Sunny','Sun/clouds','Cloudy & Sunny',\n",
    "                                                          'Sun & Clouds','Cloudy Dry','Cloud/sun','Mixed','Sun/cloud',\n",
    "                                                           'Sunny/cloudy','Cloudy Sun','Cloudy/sun','Dry/cloudy',\n",
    "                                                           'Sun/cloudy','Overcast/dry','Cloud','Dull','Dry/overcast',\n",
    "                                                          'Dark/cloudy','Cloudy/dry','Cloudy'],'Good')\n",
    "\n",
    "\n",
    "\n",
    "# Damp\n",
    "inner_london['Weather'] = inner_london['Weather'].replace(['Wet/dry','Intermittent Light Drizzle','Light Rain',\n",
    "                                                           'Lt Rain','Drizzle','Intermittent Drizzle', 'Damp','Getting Dry',\n",
    "                                                           'Dry & Wet','Slight Drizzle/dry','Dry Road Still Wet'],'Damp')\n",
    "\n",
    "# Dangerous Conditions\n",
    "inner_london['Weather'] = inner_london['Weather'].replace(['Heavy Rain','Dry/wet Road','Dry With Wet Road',\n",
    "                                                           'Hot','Snow!','Snow', 'Sleet','Very Hot',\n",
    "                                                           'Dry (road Wet)','Dry, Sunny, Hot','Very Heavy Rain',\n",
    "                                                           'Intermittent Heavy Showers','Very Hot/dry','Hot/dry',\n",
    "                                                           'Storm','Heavy Rain High Winds','V Wet','Rain Heavy',\n",
    "                                                          'Sunny (hot!)','Heavy Thunder','Overcast/rain Heavy Showers',\n",
    "                                                          'Too Cold','High Wind','Very Windy','Wet/windy','Wet/v.windy',\n",
    "                                                           'Wet Hail','Rain/hail','Foggy Wet',\n",
    "                                                           'Wet Heavy Wind', 'Wet-windy','Hailstones',\n",
    "                                                           'Short Hail Shower','Rain/sleet','Hail Stone',\n",
    "                                                          'Hail','Showers/hailstone','Rain/hailstone','Dry Chill','Dry/cold',\n",
    "                                                           'Dry Cold','Cold/sunny','Cold/cloudy',\n",
    "                                                           'Dry Very Windy', 'Dry/windy','Windy','Cold','Cloudy/windy',\n",
    "                                                           'Windy + Sunny','Sunsetting + Windy','Dark Cloudy',\n",
    "                                                           'Dry V. Cold!','Very Cool','Dry & Windy',\n",
    "                                                          'Dry but Cold or Wind','Dry/v. Windy','Dry Windy',\n",
    "                                                          'Windy At First Then Sunny','Windy Dry',\n",
    "                                                          'Dry Wet Road','Thunder'],'Dangerous_Conditions')\n",
    "\n",
    "# Consolidating 'Unknown'\n",
    "inner_london['Weather'] = inner_london['Weather'].replace(['School Out','N/a','Unknown'],'Unknown')\n",
    "\n",
    "# Transforming Nan Values into Unknown\n",
    "# Replacing nan with 'Unknown'\n",
    "inner_london.Weather = inner_london.Weather.fillna('Unknown')\n",
    "\n",
    "# Consolidating \"Dry Dark\" into \"Unknown\"\n",
    "inner_london['Weather'] = inner_london['Weather'].replace(['Dry Dark','Dry/dark','Dark/dry',\n",
    "                                                           'Dark Dry'],'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f22f2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey_wave_(year) :  8\n",
      "Site_ID :  210\n",
      "Location :  205\n",
      "Survey_date :  1596\n",
      "Weather :  283\n",
      "Time :  64\n",
      "Period :  5\n",
      "Direction :  4\n",
      "Number_of_private_cycles :  435\n",
      "Number_of_cycle_hire_bikes :  87\n",
      "Total_cycles :  479\n",
      "Day_of_week :  7\n",
      "month :  12\n",
      "season :  4\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in each column\n",
    "for col in central_london:\n",
    "  print(col,\": \", central_london[col].nunique())\n",
    "\n",
    "# More site ids vs location again.\n",
    "# May imply multiple sites in same location. Does this double count? Need to check!\n",
    "# Survey period of 8 years\n",
    "# 5 Periods of day which should be synched in same fashion with all the other city count data\n",
    "# will use london period of day definition as base.\n",
    "# 282 types of weather needs to be consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c664ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate descriptions in Weather\n",
    "# Rain\n",
    "central_london['Weather'] = central_london['Weather'].replace(['Wet','Cloudy/rain','Rain','Mix Wet/dry','Drizzle',\n",
    "                                                          'Light Showers', 'Mizzle','Windy/rain','Showers',\n",
    "                                                          'Wet/dry','Wet/damp','Shower','Drizzle/shower','Rainy',\n",
    "                                                          'wet','Cloudy with showers','Generally overcast brief shower'\n",
    "                                                          'Light Rain','Shower/dry','Spitting','Drizzle/cloudy',\n",
    "                                                          'Dry/wet','Damp', 'Dry/drizzle','Dull/damp','Dry-wet',\n",
    "                                                          'Wet/mix', 'Drizzle/wet','Wet/windy','Rain Shower',\n",
    "                                                          'Intermittent Showers','Cloudy/drizzle','Rain/drizzle',\n",
    "                                                          'Wet Road','Drizzle/dry','Drizzle/rain','Mixed Sunny + Rain',\n",
    "                                                          'Wet/rain', 'V Light Drizzle', 'Rainy', 'W','Slight Drizzle',\n",
    "                                                          'Rain Stopped', 'Stopped Raining','Wet Rain Stopped','Raining/wet',\n",
    "                                                          'Showery','Overcast/rain','Rain/wet','Rain/showers','Showers/sunny',\n",
    "                                                          'Drizzle/showers','Wet/stop Raining','Drizzle Rain','Drizzle Wet',\n",
    "                                                          'Damp/sun','Raining','Dry + Wet','Showers/cloudy','Cloudy/showers',\n",
    "                                                          'Getting Wet','Wet Road:sun','Dry But Wet Road','Drizze',\n",
    "                                                          'wet','Wettish','Light Rain','S.wet','S/w','Cold/rain',\n",
    "                                                           'Slightly Wet','Road Wet','Light Shower','Rain Damp','Wet Damp',\n",
    "                                                              'Wet - Dry','Dry - Wet','Rain Dry','Dry - Rain','Damp - Rain',\n",
    "                                                              'Wet/ Dry','S. Wet','Cloudy/ Rain','Windy/ Rain','Wet T',\n",
    "                                                              'Some Showers','Rains','Sunny/rainy','Wetr','Showers Mix',\n",
    "                                                              'Rain/dry','Rain/cloudy','Shower/wet','Wetter',\n",
    "                                                              'Heavy Rain','Heavy Shower','Heavy Shr','Down Pour',\n",
    "                                                           'Deluge','Heavy Showers', 'Shower','Rain Heavy Showers',\n",
    "                                                           'Intermitent Showers','Thunder Lightening Rain!','Very Wet',\n",
    "                                                           'V.wet','Heavy Downpour/rain','Showery','Wet Heavy Rain',\n",
    "                                                           'Wet (heavy Rain)','Wet (shower)','Blustery','V. Wet',\n",
    "                                                              'Rain & Thunder','Rain-heavy','H Rain','Wert','(rain After)',\n",
    "                                                              'Cloud/rain','Really Wet','Periods Of Rain Quite Windy',\n",
    "                                                              'Steady Rain'],'Rain')\n",
    "\n",
    "# Good\n",
    "central_london['Weather'] = central_london['Weather'].replace(['Sunny','Cloudy Sunny','Sun Setting','Good','Dry/sunny',\n",
    "                                                          'Fine + Dry', 'Fine + Hot','Bright','Dry Hot!!',\n",
    "                                                          'Dry & Sunny','Dry & Sun','Fine & Dry','Good/dry','Sun',\n",
    "                                                          'Sunny Dry','Clear and Bright', 'Fine', 'Dry/good', \n",
    "                                                          'Fine/dry', 'Warm + Dry','Dry','Dry                         9',\n",
    "                                                          'Sunny','Cloudy/sunny','Druy','Dry/hot','Dry Warm',\n",
    "                                                          'Dry/sun','Dryish','Clear And Dry','Clear and Dry','Dry, Warm',\n",
    "                                                          'Dry, Sunny, Warm','Cloudy with Clear Intervals','Clear and Warm',\n",
    "                                                          'Dry But Misty','Sunny & Warm All Day','Clear','Dry + Sunny',\n",
    "                                                          'Sunny/dry','Dr Ry','Dry Y','D','Warm/dry','Bright/dry','Dry Sunny',\n",
    "                                                          'Fair','Dry/sun','Kdry','Fine Windy',\n",
    "                                                               'Cloudy','Sunny Overcast Sunny','Sunny/cloudy',\n",
    "                                                               'Cloudy/rain/sunny','Cloudy + Sunny','Sunny + Cloudy',\n",
    "                                                               'Cloudy/sunny','Bright + Cloudy','Cloudy/dry',\n",
    "                                                               'Partly Sunny','Dull','Dry & Mild','Cloud','Overcast',\n",
    "                                                               'Mild','Overcast (No Rain)','Cloudy bright intervals',\n",
    "                                                               'Generally overcast','Cloudy with clear spells',\n",
    "                                                               'Sunny Overcast','Dry','Dry/mild', 'Clear',\n",
    "                                                               'Cloudy and Dry','Partly cloudy but dry',\n",
    "                                                          'Partly cloudy and dry','Cloudy but dry','Partly cloudy and Dry',\n",
    "                                                          'Sun/Cloudy','Clouds & Sunny','Sun/clouds','Cloudy & Sunny',\n",
    "                                                          'Sun & Clouds','Cloudy Dry','Cloud/sun','Mixed','Sun/cloud',\n",
    "                                                           'Sunny/cloudy','Cloudy Sun','Cloudy/sun','Dry/cloudy',\n",
    "                                                           'Sun/cloudy','Overcast/dry','Cloud','Dull','Dry/overcast',\n",
    "                                                          'Dark/cloudy','Cloudy/dry','Cloudy','Hazy','Partly Cloudy',\n",
    "                                                               'Drty','Dry (windy)','Fine (windy)','Sunny Cloudy',\n",
    "                                                              'Dry Dark','Dark','Dry Mon','Dry Wed','Dry Thu','Dry Fri',\n",
    "                                                              'Sun/rain','Thunder','Cloudy','Sunny Overcast Sunny',\n",
    "                                                               'Sunny/cloudy','Cloudy/rain/sunny',\n",
    "                                                           'Cloudy + Sunny','Sunny + Cloudy', 'Cloudy/sunny',\n",
    "                                                           'Bright + Cloudy','Cloudy/dry','Partly Sunny','Dull','Dry & Mild',\n",
    "                                                           'Cloud','Overcast','Mild','Overcast (No Rain)',\n",
    "                                                          'Cloudy bright intervals','Generally overcast',\n",
    "                                                           'Cloudy with clear spells','Sunny Overcast','Dry',\n",
    "                                                           'Dry/mild', 'Clear','Cloudy and Dry','Partly cloudy but dry',\n",
    "                                                          'Partly cloudy and dry','Cloudy but dry','Partly cloudy and Dry',\n",
    "                                                          'Sun/Cloudy','Clouds & Sunny','Sun/clouds','Cloudy & Sunny',\n",
    "                                                          'Sun & Clouds','Cloudy Dry','Cloud/sun','Mixed','Sun/cloud',\n",
    "                                                           'Sunny/cloudy','Cloudy Sun','Cloudy/sun','Dry/cloudy',\n",
    "                                                           'Sun/cloudy','Overcast/dry','Cloud','Dull','Dry/overcast',\n",
    "                                                          'Dark/cloudy','Cloudy/dry','Cloudy','Hazy','Partly Cloudy',\n",
    "                                                               'Drty','Dry (windy)','Fine (windy)','Sunny Cloudy',\n",
    "                                                              'Dry Dark','Dark','Dry Mon','Dry Wed','Dry Thu','Dry Fri',\n",
    "                                                              'Sun/rain','Thunder','Ddry','Dy','Dry/sunny/cold','Fine Cold',\n",
    "                                                              'Cold Dry','Dry & Cold','Dry And Fine','Dry And Sunny',\n",
    "                                                              'Dry And Warm','Fine And Dry','Warm + Sunny','Warm And Humid',\n",
    "                                                              'Warm And Windy','Overcast And Dull','Cloudy And Warm',\n",
    "                                                              'Sunny Periods And Warm','Dry And Windy','Dry And Very Windy',\n",
    "                                                              'Warm Sunny And Windy','Hot And Humid','Mild And Sunny',\n",
    "                                                               'Warm And Overcast','Sunny & Windy','Windy/cloudy',\n",
    "                                                              'Dry/gusty','Coldish','Windy/dry','Dry But A Bit Windy',\n",
    "                                                               'Sunny Cold','Cold At First Then Warm/sunny',\n",
    "                                                              'Warm & Sunny Chilly Later','Fine + Dry Chilly At First',\n",
    "                                                               'Fine & Sunny','dry','A Bit Chilly At First',\n",
    "                                                               'Warm With A Slight Wind','Cold Then Dry And Windy',\n",
    "                                                               'Dry And Overcast','Warm + Sunny Cloudy + Windy',\n",
    "                                                              'Dry 3/4 Dry','Sunny Until Evening But Windy',\n",
    "                                                               'Winds Rather Chilly','Warm','Sunny But Very Windy',\n",
    "                                                               'Now Starts To Get Chilly'],'Good')\n",
    "\n",
    "\n",
    "# Light Rain\n",
    "central_london['Weather'] = central_london['Weather'].replace(['Wet/dry','Intermittent Light Drizzle','Light Rain',\n",
    "                                                           'Lt Rain','Drizzle','Intermittent Drizzle', 'Damp','Getting Dry',\n",
    "                                                           'Dry & Wet','Slight Drizzle/dry','Wet Intermittently',\n",
    "                                                               'Light Rain','V Light Rain','Dry Wet Road','Dry A.m Wet P.m',\n",
    "                                                               'Mist','Road Drying Sun Out','Wetish','Light Shrs',\n",
    "                                                              'Fine Drizzle','V Light Shrs','L/rain','Rain Stopped-dry',\n",
    "                                                              'V Lt Rain','V.light Rain','Dry (+brief Speels Of Drizzle',\n",
    "                                                              'Wet (spitting)','Drizzly Rain','Almost Dry','Damp & Drizzly',\n",
    "                                                              'Dry Road Wet With Leaves','Wet Drizzle','No Rain Wet Roads',\n",
    "                                                              'Dry But Wet Roads','Very Light Rain','Light Drizzle',\n",
    "                                                              'Dry/wet Road Surface','V Light Showers','V. Light Rain',\n",
    "                                                              'Wet/cloudy','Wet/sunny','Dry Road Still Wet',\n",
    "                                                              '2 Snowflakes Otherwise Dry','Wet-dry','Dry/drizzly',\n",
    "                                                              'Wet/light Showers','Wet/drizzle','Wet And Windy',\n",
    "                                                              'Drizzling','Drizzle Damp','Windy Showery','Wet + Dry',\n",
    "                                                              'V.light Drizzle','Very Light Drizzle','Drying Up','Wet Again',\n",
    "                                                              'Cold Sunny Rain','Wet First Then Dry','Wetr First Then Dry',\n",
    "                                                              'Dry With Intermitent Rain','(drizzle)','Damp/misty/wet',\n",
    "                                                              'Dry But Rain Threatening','Slight Drizzle Till End',\n",
    "                                                              'Damp/misty','Cold & Dry Early Rain Later',\n",
    "                                                              'Wet ','Windy/drizzle','Intermitent Light Showers',\n",
    "                                                              'Intermitent Light Rain','A Few Rain Showers','Drizzly',\n",
    "                                                              'Rain Looking Likely','A Few Drops Of Rain'],'Damp')\n",
    "\n",
    "# Dangerous Weather\n",
    "central_london['Weather'] = central_london['Weather'].replace(['Heavy Rain','Dry/wet Road','Dry With Wet Road',\n",
    "                                                           'Hot','Snow!','Snow', 'Sleet','Very Hot',\n",
    "                                                           'Dry (road Wet)','Dry, Sunny, Hot','Very Heavy Rain',\n",
    "                                                           'Intermittent Heavy Showers','Very Hot/dry','Hot/dry',\n",
    "                                                           'Storm','Heavy Rain High Winds','V Wet','Rain Heavy',\n",
    "                                                          'Sunny (hot!)','Heavy Thunder','Overcast/rain Heavy Showers',\n",
    "                                                          'Too Cold','High Wind','Very Windy','Dry & Very Windy',\n",
    "                                                              'Very Hot Dry','Wet/windy','Wet/v.windy','Wet Hail',\n",
    "                                                               'Rain/hail','Foggy Wet',\n",
    "                                                           'Wet Heavy Wind', 'Wet-windy','Hailstones',\n",
    "                                                           'Short Hail Shower','Rain/sleet','Hail Stone',\n",
    "                                                          'Hail','Showers/hailstone','Rain/hailstone','Cold/ Rain',\n",
    "                                                              'Foggy','Wet & Windy','Wet + Windy','Rain/wind',\n",
    "                                                              'Wet (windy)','Occasional Lt Snow Shrs',\n",
    "                                                              'Wet And Very Windy','Dry Chill','Dry/cold','Dry Cold',\n",
    "                                                               'Cold/sunny','Cold/cloudy',\n",
    "                                                           'Dry Very Windy', 'Dry/windy','Windy','Cold','Cloudy/windy',\n",
    "                                                           'Windy + Sunny','Sunsetting + Windy','Dark Cloudy',\n",
    "                                                           'Dry V. Cold!','Very Cool','Dry & Windy',\n",
    "                                                          'Dry but Cold or Wind','Dry/v. Windy','Dry Windy',\n",
    "                                                          'Windy At First Then Sunny','Windy Dry','Cold Windy Dry',\n",
    "                                                              'Cold/dry','Some Heavy Showers','Very Cold/dry',\n",
    "                                                              'Foggy/v Cold','Hail Shower','Snowing','Wet/ Snowing',\n",
    "                                                              'Heavy Snow','Dry/very Windy','Very Windy & Cold',\n",
    "                                                              'Wet Light Hailstone','Heavy Showers Throughout Day',\n",
    "                                                              'High Winds & Spits Of Rain','Fine V Cold',\n",
    "                                                              'Dry (frost & Fog)','V Cold Showers','Cold/showery',\n",
    "                                                              'Light Showers Inc Some Hail','Cloudy/hail','Cold Wind',\n",
    "                                                              'Hot & Sunny','Hot And Sunny','Dry/windy/strong Wind',\n",
    "                                                              'Hot + Humid','Very Cold Sunny But Windy'],'Dangerous_Conditions')\n",
    "\n",
    "# Consolidating 'Unknown'\n",
    "central_london['Weather'] = central_london['Weather'].replace(['School Out','N/a','Unknown','Dark Sunny',\n",
    "                                                              'Wed','Warm & Sunny But Windy & Cold'],'Unknown')\n",
    "\n",
    "# Transforming Nan Values into Unknown\n",
    "# Replacing nan with 'Unknown'\n",
    "central_london.Weather = central_london.Weather.fillna('Unknown')\n",
    "\n",
    "# Consolidating \"Dry Dark\"\n",
    "central_london['Weather'] = central_london['Weather'].replace(['Dry Dark','Dry/dark','Dark/dry',\n",
    "                                                           'Dark Dry', 'X'],'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "077f7af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey_wave_(year) :  7\n",
      "Site_ID :  451\n",
      "Location :  431\n",
      "Survey_date :  435\n",
      "Weather :  124\n",
      "Time :  64\n",
      "Period :  5\n",
      "Direction :  4\n",
      "Number_of_male_cycles :  55\n",
      "Number_of_female_cycles :  20\n",
      "Number_of_unknown_cycles :  11\n",
      "Total_cycles :  65\n",
      "Day_of_week :  7\n",
      "month :  12\n",
      "season :  4\n"
     ]
    }
   ],
   "source": [
    "# Count unique values in each column\n",
    "for col in outer_london:\n",
    "  print(col,\": \", outer_london[col].nunique())\n",
    "\n",
    "# More site ids vs location\n",
    "# May imply multiple sites in same location. Need to check for double count.\n",
    "# Survey period of over 7 years\n",
    "# 5 Periods of day which should be synched in same fashion with all the other city count data\n",
    "# will use london period of day definition as base.\n",
    "# 123 types of weather needs to be consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a1a61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate descriptions in Weather\n",
    "# Rain\n",
    "outer_london['Weather'] = outer_london['Weather'].replace(['Wet','Showers','Rain','Cloudy + Rain','Rain & Cloudy',\n",
    "                                                          'Raining', 'Rain/cloudy','Wet/thunder','Light Showers',\n",
    "                                                          'Rain/showers','W','Wey','Drizzle/shower','Rainy',\n",
    "                                                          'wet','Cloudy with showers','Generally overcast brief shower',\n",
    "                                                          'Heavy Rain','Heavy Shower','Heavy Shr','Down Pour',\n",
    "                                                           'Deluge','Heavy Showers', 'Shower','Rain Heavy Showers',\n",
    "                                                           'Intermitent Showers','Thunder Lightening Rain!','Very Wet',\n",
    "                                                           'V.wet','Heavy Downpour/rain','Showery','Wet Heavy Rain',\n",
    "                                                           'Wet (heavy Rain)'],'Rain')\n",
    "\n",
    "# Good\n",
    "outer_london['Weather'] = outer_london['Weather'].replace(['Cloudy','Sunny Overcast Sunny','Sunny/cloudy','Cloudy/rain/sunny',\n",
    "                                                           'Cloudy + Sunny','Sunny + Cloudy', 'Cloudy/sunny',\n",
    "                                                           'Bright + Cloudy','Cloudy/dry','Partly Sunny','Dull','Dry & Mild',\n",
    "                                                           'Cloud','Overcast','Mild','Overcast (No Rain)',\n",
    "                                                          'Cloudy bright intervals','Generally overcast',\n",
    "                                                           'Cloudy with clear spells','Sunny Overcast','Dry',\n",
    "                                                           'Dry/mild', 'Clear','Cloudy with clear spells',\n",
    "                                                          'Sunny Overcast', 'Sunny','Cloudy Sunny','Sun Setting','Good',\n",
    "                                                           'Dry/sunny','Fine + Dry', 'Fine + Hot','Bright','Dry Hot!!',\n",
    "                                                          'Dry & Sunny','Dry & Sun','Fine & Dry','Good/dry','Sun',\n",
    "                                                          'Sunny Dry','Clear and Bright', 'Fine', 'Dry/good', \n",
    "                                                          'Fine/dry','Warm + Dry','D'],'Good')\n",
    "# Damp\n",
    "outer_london['Weather'] = outer_london['Weather'].replace(['Wet/dry','Intermittent Light Drizzle',\n",
    "                                                           'Light Rain','Lt Rain','Drizzle','Intermittent Drizzle', 'Damp',\n",
    "                                                           'Getting Dry','Dry & Wet','Dry/wet',],'Damp')\n",
    "\n",
    "\n",
    "# Dangerous Conditions\n",
    "outer_london['Weather'] = outer_london['Weather'].replace(['Dry Chill','Dry/cold','Dry Cold','Cold/sunny','Cold/cloudy',\n",
    "                                                           'Dry Very Windy', 'Dry/windy','Windy','Cold','Cloudy/windy',\n",
    "                                                           'Windy + Sunny','Sunsetting + Windy','Dark Cloudy',\n",
    "                                                           'Dry V. Cold!','Very Cool','Wet/windy','Wet/v.windy','Wet Hail',\n",
    "                                                           'Rain/hail','Foggy Wet','Wet Heavy Wind', 'Wet-windy','Hailstones',\n",
    "                                                           'Short Hail Shower','Heavy Rain','Dry/wet Road','Dry With Wet Road',\n",
    "                                                           'Hot','Snow!','Snow', 'Sleet','Very Hot','Dry (road Wet)'],\n",
    "                                                          'Dangerous_Conditions')\n",
    "\n",
    "# Replacing nan with 'Unknown'\n",
    "outer_london.Weather = outer_london.Weather.fillna('Unknown')\n",
    "\n",
    "# Consolidating \"Unknown\"\n",
    "outer_london['Weather'] = outer_london['Weather'].replace(['Dry Dark','Dry/dark','Dark/dry','Dark Dry', 'N/a'],'Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa91ca",
   "metadata": {},
   "source": [
    "### Summarising Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2cd41e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "date           0\n",
       "day_of_week    0\n",
       "month          0\n",
       "season         0\n",
       "year           0\n",
       "hour           0\n",
       "time_of_day    0\n",
       "counts         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "ny_counts.isnull().sum()\n",
    "\n",
    "# No Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc69c980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiteID           0\n",
       "Month            0\n",
       "Year             0\n",
       "TotalCount       0\n",
       "Early_Morning    0\n",
       "AM_Peak          0\n",
       "PM_Peak          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "sydney_counts.isnull().sum()\n",
    "\n",
    "# No Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8006b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survey_wave_(year)            0\n",
       "Site_ID                       0\n",
       "Location                      0\n",
       "Survey_date                   0\n",
       "Weather                       0\n",
       "Time                          6\n",
       "Period                        6\n",
       "Direction                     0\n",
       "Number_of_private_cycles      0\n",
       "Number_of_cycle_hire_bikes    0\n",
       "Total_cycles                  0\n",
       "Day_of_week                   0\n",
       "month                         0\n",
       "season                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "inner_london.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9544139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survey_wave_(year)            0\n",
       "Site_ID                       0\n",
       "Location                      0\n",
       "Survey_date                   0\n",
       "Weather                       0\n",
       "Time                          0\n",
       "Period                        0\n",
       "Direction                     0\n",
       "Number_of_private_cycles      0\n",
       "Number_of_cycle_hire_bikes    0\n",
       "Total_cycles                  0\n",
       "Day_of_week                   0\n",
       "month                         0\n",
       "season                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "central_london.isnull().sum()\n",
    "\n",
    "# No Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "675df2c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survey_wave_(year)          0\n",
       "Site_ID                     0\n",
       "Location                    0\n",
       "Survey_date                 0\n",
       "Weather                     0\n",
       "Time                        0\n",
       "Period                      0\n",
       "Direction                   0\n",
       "Number_of_male_cycles       0\n",
       "Number_of_female_cycles     0\n",
       "Number_of_unknown_cycles    0\n",
       "Total_cycles                0\n",
       "Day_of_week                 0\n",
       "month                       0\n",
       "season                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "outer_london.isnull().sum()\n",
    "\n",
    "# No Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4dbcd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4167507 entries, 0 to 4167506\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   id           int64         \n",
      " 1   date         datetime64[ns]\n",
      " 2   day_of_week  object        \n",
      " 3   month        int64         \n",
      " 4   season       object        \n",
      " 5   year         int64         \n",
      " 6   hour         int64         \n",
      " 7   time_of_day  object        \n",
      " 8   counts       int64         \n",
      "dtypes: datetime64[ns](1), int64(5), object(3)\n",
      "memory usage: 286.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 523624 entries, 36864 to 378879\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   Survey_wave_(year)          523624 non-null  int32         \n",
      " 1   Site_ID                     523624 non-null  object        \n",
      " 2   Location                    523624 non-null  object        \n",
      " 3   Survey_date                 523624 non-null  datetime64[ns]\n",
      " 4   Weather                     523624 non-null  object        \n",
      " 5   Time                        523618 non-null  object        \n",
      " 6   Period                      523618 non-null  object        \n",
      " 7   Direction                   523624 non-null  object        \n",
      " 8   Number_of_private_cycles    523624 non-null  float64       \n",
      " 9   Number_of_cycle_hire_bikes  523624 non-null  float64       \n",
      " 10  Total_cycles                523624 non-null  float64       \n",
      " 11  Day_of_week                 523624 non-null  object        \n",
      " 12  month                       523624 non-null  int64         \n",
      " 13  season                      523624 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(3), int32(1), int64(1), object(8)\n",
      "memory usage: 57.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 758099 entries, 27328 to 678591\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   Survey_wave_(year)          758099 non-null  int64         \n",
      " 1   Site_ID                     758099 non-null  object        \n",
      " 2   Location                    758099 non-null  object        \n",
      " 3   Survey_date                 758099 non-null  datetime64[ns]\n",
      " 4   Weather                     758099 non-null  object        \n",
      " 5   Time                        758099 non-null  object        \n",
      " 6   Period                      758099 non-null  object        \n",
      " 7   Direction                   758099 non-null  object        \n",
      " 8   Number_of_private_cycles    758099 non-null  float64       \n",
      " 9   Number_of_cycle_hire_bikes  758099 non-null  float64       \n",
      " 10  Total_cycles                758099 non-null  float64       \n",
      " 11  Day_of_week                 758099 non-null  object        \n",
      " 12  month                       758099 non-null  int64         \n",
      " 13  season                      758099 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(3), int64(2), object(8)\n",
      "memory usage: 86.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 375659 entries, 6144 to 165759\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   Survey_wave_(year)        375659 non-null  int64         \n",
      " 1   Site_ID                   375659 non-null  object        \n",
      " 2   Location                  375659 non-null  object        \n",
      " 3   Survey_date               375659 non-null  datetime64[ns]\n",
      " 4   Weather                   375659 non-null  object        \n",
      " 5   Time                      375659 non-null  object        \n",
      " 6   Period                    375659 non-null  object        \n",
      " 7   Direction                 375659 non-null  object        \n",
      " 8   Number_of_male_cycles     375659 non-null  int64         \n",
      " 9   Number_of_female_cycles   375659 non-null  int64         \n",
      " 10  Number_of_unknown_cycles  375659 non-null  int64         \n",
      " 11  Total_cycles              375659 non-null  int64         \n",
      " 12  Day_of_week               375659 non-null  object        \n",
      " 13  month                     375659 non-null  int64         \n",
      " 14  season                    375659 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(6), object(8)\n",
      "memory usage: 45.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2186 entries, 0 to 2214\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   SiteID         2186 non-null   int64 \n",
      " 1   Month          2186 non-null   object\n",
      " 2   Year           2186 non-null   int64 \n",
      " 3   TotalCount     2186 non-null   int64 \n",
      " 4   Early_Morning  2186 non-null   int64 \n",
      " 5   AM_Peak        2186 non-null   int64 \n",
      " 6   PM_Peak        2186 non-null   int64 \n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 136.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Review all metadata again \n",
    "ny_counts.info()\n",
    "inner_london.info()\n",
    "central_london.info()\n",
    "outer_london.info()\n",
    "sydney_counts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37406a",
   "metadata": {},
   "source": [
    "## Merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83937476",
   "metadata": {},
   "source": [
    "### Concatenate London DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16632340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging London Dataframes first to check output as this is the base Df. \n",
    "london = pd.concat([outer_london, central_london, inner_london])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf67e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1657382 entries, 6144 to 378879\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count    Dtype         \n",
      "---  ------                      --------------    -----         \n",
      " 0   Survey_wave_(year)          1657382 non-null  int64         \n",
      " 1   Site_ID                     1657382 non-null  object        \n",
      " 2   Location                    1657382 non-null  object        \n",
      " 3   Survey_date                 1657382 non-null  datetime64[ns]\n",
      " 4   Weather                     1657382 non-null  object        \n",
      " 5   Time                        1657376 non-null  object        \n",
      " 6   Period                      1657376 non-null  object        \n",
      " 7   Direction                   1657382 non-null  object        \n",
      " 8   Number_of_male_cycles       375659 non-null   float64       \n",
      " 9   Number_of_female_cycles     375659 non-null   float64       \n",
      " 10  Number_of_unknown_cycles    375659 non-null   float64       \n",
      " 11  Total_cycles                1657382 non-null  float64       \n",
      " 12  Day_of_week                 1657382 non-null  object        \n",
      " 13  month                       1657382 non-null  int64         \n",
      " 14  season                      1657382 non-null  object        \n",
      " 15  Number_of_private_cycles    1281723 non-null  float64       \n",
      " 16  Number_of_cycle_hire_bikes  1281723 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(2), object(8)\n",
      "memory usage: 227.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# View Metadata\n",
    "london.info()\n",
    "\n",
    "# London rows all add up correctly so merge is successful. \n",
    "# Expecting some null values now as inner and central london dfs didnt have gender info\n",
    "# Expecting some null values now as outer london df didnt have cycle ownership/rental info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0bb14a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survey_wave_(year)                  0\n",
       "Site_ID                             0\n",
       "Location                            0\n",
       "Survey_date                         0\n",
       "Weather                             0\n",
       "Time                                6\n",
       "Period                              6\n",
       "Direction                           0\n",
       "Number_of_male_cycles         1281723\n",
       "Number_of_female_cycles       1281723\n",
       "Number_of_unknown_cycles      1281723\n",
       "Total_cycles                        0\n",
       "Day_of_week                         0\n",
       "month                               0\n",
       "season                              0\n",
       "Number_of_private_cycles       375659\n",
       "Number_of_cycle_hire_bikes     375659\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "london.isnull().sum()\n",
    "\n",
    "# All aligns as expected. \n",
    "# Will drop the 6 rows where period and time has null values\n",
    "# 6 rows being deleted will not impact data with 1.287mio rows and doesnt merit time to investigate these.\n",
    "# Gender & Cycle ownership data was already missing from some of the original data.\n",
    "# The missing rows add up to the sum of the original data where the data was missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40c243de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 6 rows where missing values in Time column\n",
    "london = london.dropna(subset=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "539dca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the Count Data from london with spatial data\n",
    "# Pull in the Spatial data\n",
    "bike_site = pd.read_excel(\"London_Biking_sites_reconv.xlsx\")\n",
    "\n",
    "# Contains additional data \n",
    "# The base data's spatial information has been converted into Longtitude & Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "102dd15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2023 entries, 0 to 2022\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   UnqID                    2023 non-null   object \n",
      " 1   ProgID                   2023 non-null   object \n",
      " 2   SurveyDescription        2023 non-null   object \n",
      " 3   Easting                  2023 non-null   float64\n",
      " 4   Northing                 2023 non-null   float64\n",
      " 5   latitude                 2023 non-null   float64\n",
      " 6   longitude                2023 non-null   float64\n",
      " 7   Location                 2023 non-null   object \n",
      " 8   Borough                  2023 non-null   object \n",
      " 9   Functional cycling area  2021 non-null   object \n",
      "dtypes: float64(4), object(6)\n",
      "memory usage: 158.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Look at Metadata\n",
    "bike_site.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd9e2991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnqID                      0\n",
       "ProgID                     0\n",
       "SurveyDescription          0\n",
       "Easting                    0\n",
       "Northing                   0\n",
       "latitude                   0\n",
       "longitude                  0\n",
       "Location                   0\n",
       "Borough                    0\n",
       "Functional cycling area    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "bike_site.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef39a81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnqID</th>\n",
       "      <th>ProgID</th>\n",
       "      <th>SurveyDescription</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Northing</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Functional cycling area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>OUTCY027</td>\n",
       "      <td>OUTCY</td>\n",
       "      <td>Outer area cycle surveys</td>\n",
       "      <td>525837.763292</td>\n",
       "      <td>169102.364207</td>\n",
       "      <td>51.406990</td>\n",
       "      <td>-0.192136</td>\n",
       "      <td>Morden Road</td>\n",
       "      <td>Merton</td>\n",
       "      <td>Outer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>QWPCY171</td>\n",
       "      <td>QWPCY</td>\n",
       "      <td>Quietway cycle surveys</td>\n",
       "      <td>512260.470000</td>\n",
       "      <td>181056.740000</td>\n",
       "      <td>51.517290</td>\n",
       "      <td>-0.383476</td>\n",
       "      <td>Grand Union Canal (Spikes Bridge moorings)</td>\n",
       "      <td>Ealing</td>\n",
       "      <td>Outer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>OUTCY201</td>\n",
       "      <td>OUTCY</td>\n",
       "      <td>Outer area cycle surveys</td>\n",
       "      <td>517645.371641</td>\n",
       "      <td>185310.044807</td>\n",
       "      <td>51.554420</td>\n",
       "      <td>-0.304482</td>\n",
       "      <td>Hawardene Road</td>\n",
       "      <td>Brent</td>\n",
       "      <td>Outer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>QWPCY255</td>\n",
       "      <td>QWPCY</td>\n",
       "      <td>Quietway cycle surveys</td>\n",
       "      <td>514728.000000</td>\n",
       "      <td>182197.000000</td>\n",
       "      <td>51.527041</td>\n",
       "      <td>-0.347551</td>\n",
       "      <td>Ruislip Road East</td>\n",
       "      <td>Ealing</td>\n",
       "      <td>Outer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CENCY044</td>\n",
       "      <td>CENCY</td>\n",
       "      <td>Central area cycle surveys</td>\n",
       "      <td>531647.290000</td>\n",
       "      <td>181040.000000</td>\n",
       "      <td>51.512958</td>\n",
       "      <td>-0.104224</td>\n",
       "      <td>New Bridge Street</td>\n",
       "      <td>City of London</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UnqID ProgID           SurveyDescription        Easting  \\\n",
       "1310  OUTCY027  OUTCY    Outer area cycle surveys  525837.763292   \n",
       "1905  QWPCY171  QWPCY      Quietway cycle surveys  512260.470000   \n",
       "1484  OUTCY201  OUTCY    Outer area cycle surveys  517645.371641   \n",
       "1989  QWPCY255  QWPCY      Quietway cycle surveys  514728.000000   \n",
       "43    CENCY044  CENCY  Central area cycle surveys  531647.290000   \n",
       "\n",
       "           Northing   latitude  longitude  \\\n",
       "1310  169102.364207  51.406990  -0.192136   \n",
       "1905  181056.740000  51.517290  -0.383476   \n",
       "1484  185310.044807  51.554420  -0.304482   \n",
       "1989  182197.000000  51.527041  -0.347551   \n",
       "43    181040.000000  51.512958  -0.104224   \n",
       "\n",
       "                                        Location         Borough  \\\n",
       "1310                                 Morden Road          Merton   \n",
       "1905  Grand Union Canal (Spikes Bridge moorings)          Ealing   \n",
       "1484                              Hawardene Road           Brent   \n",
       "1989                           Ruislip Road East          Ealing   \n",
       "43                             New Bridge Street  City of London   \n",
       "\n",
       "     Functional cycling area  \n",
       "1310                   Outer  \n",
       "1905                   Outer  \n",
       "1484                   Outer  \n",
       "1989                   Outer  \n",
       "43                   Central  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Data Sample\n",
    "bike_site.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8497931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Column on spatial data to align with Count Data\n",
    "bike_site.rename(columns = {\"UnqID\": \"Site_ID\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4747d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to remove space in column names\n",
    "bike_site.columns = bike_site.columns.str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8573399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can merge spatial data with count data using site_id as key\n",
    "london_complete = pd.merge(london, bike_site, on=\"Site_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "878427be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1657376 entries, 0 to 1657375\n",
      "Data columns (total 26 columns):\n",
      " #   Column                      Non-Null Count    Dtype         \n",
      "---  ------                      --------------    -----         \n",
      " 0   Survey_wave_(year)          1657376 non-null  int64         \n",
      " 1   Site_ID                     1657376 non-null  object        \n",
      " 2   Location_x                  1657376 non-null  object        \n",
      " 3   Survey_date                 1657376 non-null  datetime64[ns]\n",
      " 4   Weather                     1657376 non-null  object        \n",
      " 5   Time                        1657376 non-null  object        \n",
      " 6   Period                      1657376 non-null  object        \n",
      " 7   Direction                   1657376 non-null  object        \n",
      " 8   Number_of_male_cycles       375659 non-null   float64       \n",
      " 9   Number_of_female_cycles     375659 non-null   float64       \n",
      " 10  Number_of_unknown_cycles    375659 non-null   float64       \n",
      " 11  Total_cycles                1657376 non-null  float64       \n",
      " 12  Day_of_week                 1657376 non-null  object        \n",
      " 13  month                       1657376 non-null  int64         \n",
      " 14  season                      1657376 non-null  object        \n",
      " 15  Number_of_private_cycles    1281717 non-null  float64       \n",
      " 16  Number_of_cycle_hire_bikes  1281717 non-null  float64       \n",
      " 17  ProgID                      1657376 non-null  object        \n",
      " 18  SurveyDescription           1657376 non-null  object        \n",
      " 19  Easting                     1657376 non-null  float64       \n",
      " 20  Northing                    1657376 non-null  float64       \n",
      " 21  latitude                    1657376 non-null  float64       \n",
      " 22  longitude                   1657376 non-null  float64       \n",
      " 23  Location_y                  1657376 non-null  object        \n",
      " 24  Borough                     1657376 non-null  object        \n",
      " 25  Functional_cycling_area     1657376 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(10), int64(2), object(13)\n",
      "memory usage: 341.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# View Metadata of combined df\n",
    "london_complete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36261782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey_wave_(year)</th>\n",
       "      <th>Site_ID</th>\n",
       "      <th>Location_x</th>\n",
       "      <th>Survey_date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Time</th>\n",
       "      <th>Period</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Number_of_male_cycles</th>\n",
       "      <th>Number_of_female_cycles</th>\n",
       "      <th>...</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>Number_of_private_cycles</th>\n",
       "      <th>Number_of_cycle_hire_bikes</th>\n",
       "      <th>SurveyDescription</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Functional_cycling_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1655524</th>\n",
       "      <td>2017</td>\n",
       "      <td>INNCY454</td>\n",
       "      <td>Upland Road</td>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1100 - 1115</td>\n",
       "      <td>Inter-peak (10:00-16:00)</td>\n",
       "      <td>Eastbound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Inner area cycle surveys</td>\n",
       "      <td>51.457236</td>\n",
       "      <td>-0.068820</td>\n",
       "      <td>Southwark</td>\n",
       "      <td>Inner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105315</th>\n",
       "      <td>2021</td>\n",
       "      <td>CENCY197</td>\n",
       "      <td>Juxton Street</td>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>Good</td>\n",
       "      <td>1545 - 1600</td>\n",
       "      <td>Inter-peak (10:00-16:00)</td>\n",
       "      <td>Eastbound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>10</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Central area cycle surveys</td>\n",
       "      <td>51.494097</td>\n",
       "      <td>-0.115769</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survey_wave_(year)   Site_ID     Location_x Survey_date  Weather  \\\n",
       "1655524                2017  INNCY454    Upland Road  2021-12-07  Unknown   \n",
       "1105315                2021  CENCY197  Juxton Street  2021-10-09     Good   \n",
       "\n",
       "                Time                    Period  Direction  \\\n",
       "1655524  1100 - 1115  Inter-peak (10:00-16:00)  Eastbound   \n",
       "1105315  1545 - 1600  Inter-peak (10:00-16:00)  Eastbound   \n",
       "\n",
       "         Number_of_male_cycles  Number_of_female_cycles  ...  Day_of_week  \\\n",
       "1655524                    NaN                      NaN  ...      Tuesday   \n",
       "1105315                    NaN                      NaN  ...     Saturday   \n",
       "\n",
       "         month  season  Number_of_private_cycles Number_of_cycle_hire_bikes  \\\n",
       "1655524     12  Winter                       0.0                        0.0   \n",
       "1105315     10  Autumn                       2.0                        0.0   \n",
       "\n",
       "                  SurveyDescription   latitude longitude    Borough  \\\n",
       "1655524    Inner area cycle surveys  51.457236 -0.068820  Southwark   \n",
       "1105315  Central area cycle surveys  51.494097 -0.115769    Lambeth   \n",
       "\n",
       "         Functional_cycling_area  \n",
       "1655524                    Inner  \n",
       "1105315                  Central  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Sample\n",
    "london_complete.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f28bdba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove overlapping spatial data\n",
    "london_complete = london_complete.drop(['ProgID', 'Easting', 'Northing', 'Location_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab3adbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all column names to lower case to ease recalling them for analysis\n",
    "london_complete = london_complete.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51ee0edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some columns to more logical names without changing underlying data dictionary\n",
    "london_complete = london_complete.rename(columns={'location_x': 'location', 'survey_wave_(year)': 'survey_year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d51444cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survey_year</th>\n",
       "      <th>site_id</th>\n",
       "      <th>location</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>weather</th>\n",
       "      <th>time</th>\n",
       "      <th>period</th>\n",
       "      <th>direction</th>\n",
       "      <th>number_of_male_cycles</th>\n",
       "      <th>number_of_female_cycles</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>number_of_private_cycles</th>\n",
       "      <th>number_of_cycle_hire_bikes</th>\n",
       "      <th>surveydescription</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>borough</th>\n",
       "      <th>functional_cycling_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1233971</th>\n",
       "      <td>2016</td>\n",
       "      <td>INNCY367</td>\n",
       "      <td>Brisbane Avenue</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>Good</td>\n",
       "      <td>0715 - 0730</td>\n",
       "      <td>AM peak (07:00-10:00)</td>\n",
       "      <td>Southbound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>4</td>\n",
       "      <td>Spring</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Inner area cycle surveys</td>\n",
       "      <td>51.414532</td>\n",
       "      <td>-0.195420</td>\n",
       "      <td>Merton</td>\n",
       "      <td>Inner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639010</th>\n",
       "      <td>2021</td>\n",
       "      <td>INNCY194</td>\n",
       "      <td>Mortimer Road</td>\n",
       "      <td>2021-07-21</td>\n",
       "      <td>Good</td>\n",
       "      <td>1030 - 1045</td>\n",
       "      <td>Inter-peak (10:00-16:00)</td>\n",
       "      <td>Westbound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>7</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Inner area cycle surveys</td>\n",
       "      <td>51.531983</td>\n",
       "      <td>-0.218202</td>\n",
       "      <td>Brent</td>\n",
       "      <td>Inner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         survey_year   site_id         location survey_date weather  \\\n",
       "1233971         2016  INNCY367  Brisbane Avenue  2016-04-28    Good   \n",
       "1639010         2021  INNCY194    Mortimer Road  2021-07-21    Good   \n",
       "\n",
       "                time                    period   direction  \\\n",
       "1233971  0715 - 0730     AM peak (07:00-10:00)  Southbound   \n",
       "1639010  1030 - 1045  Inter-peak (10:00-16:00)   Westbound   \n",
       "\n",
       "         number_of_male_cycles  number_of_female_cycles  ...  day_of_week  \\\n",
       "1233971                    NaN                      NaN  ...     Thursday   \n",
       "1639010                    NaN                      NaN  ...    Wednesday   \n",
       "\n",
       "         month  season  number_of_private_cycles number_of_cycle_hire_bikes  \\\n",
       "1233971      4  Spring                       0.0                        0.0   \n",
       "1639010      7  Summer                       1.0                        0.0   \n",
       "\n",
       "                surveydescription   latitude longitude  borough  \\\n",
       "1233971  Inner area cycle surveys  51.414532 -0.195420   Merton   \n",
       "1639010  Inner area cycle surveys  51.531983 -0.218202    Brent   \n",
       "\n",
       "         functional_cycling_area  \n",
       "1233971                    Inner  \n",
       "1639010                    Inner  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_complete.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38923748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the combined dataframe as a new CSV for backup\n",
    "london_complete.to_csv('london_count_and_site_Saurav_071022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8189f3",
   "metadata": {},
   "source": [
    "# Exploring Twitter Data about Cycling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7582fe68",
   "metadata": {},
   "source": [
    "Task here is to extract the most recent posts on Twitter about Cycling. From these, the objectives are:\n",
    "- Plot on a map where the topic is most Trending and to see if any of the three cities being analysed are amongst them\n",
    "- Get an overview of the sentiment expressed in such posts\n",
    "- Get an overview of the most common words used in such posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970fe06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the YAML file and Twitter keys over to this Jupyter Notebook before you start to work.\n",
    "# Import the yaml file - remember to specify the whole path and use / between directories\n",
    "twitter_creds = yaml.safe_load(open('twitter_tmp.yaml', 'r').read())\n",
    "\n",
    "# To investigate the Tweets & Sentiment Analysis\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass Tweepy credentials\n",
    "tweepy_api = Twitter(auth=OAuth(twitter_creds['access_token'],\n",
    "                                 twitter_creds['access_token_secret'], \n",
    "                                 twitter_creds['api_key'],\n",
    "                                 twitter_creds['api_secret_key'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass your Twitter credentials.\n",
    "twitter_api = Twitter(auth=OAuth(twitter_creds['access_token'],\n",
    "                                 twitter_creds['access_token_secret'], \n",
    "                                 twitter_creds['api_key'],\n",
    "                                 twitter_creds['api_secret_key'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e194e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Tweepy connection\n",
    "print(tweepy_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc719323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Twitter connection\n",
    "print(twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for the term cycling on Twitter\n",
    "# Ordered by recency\n",
    "# Filtering for only those Tweets which have point coordinates or twitter places\n",
    "\n",
    "# Note that the free Twitter API being used here only allows access to the seven most recent days of tweets\n",
    "\n",
    "q = {'q':'cycling', 'count':100, 'result_type':'recent', 'has':'geo'}\n",
    "\n",
    "# Results as an empty list.\n",
    "results = []\n",
    "\n",
    "while len(results) < 40:\n",
    "    query = twitter_api.search.tweets(**q)\n",
    "    q['max_id'] = query['search_metadata']['next_results'].split('&')[0].split('?max_id=')[1]\n",
    "    results.append(query)\n",
    "    \n",
    "# Determine the number of results.\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the results in a DataFrame for NLP Analysis\n",
    "df2 = pd.concat([pd.DataFrame(_['statuses']) for _ in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee4f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Metadata\n",
    "df2.info()\n",
    "\n",
    "# Not much geo data captured. \n",
    "# Leave and return later \n",
    "# Check with Norah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine values of the output\n",
    "df2 = df2['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View one raw result\n",
    "# Confirms that the body of the post is stored here\n",
    "df2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c6eac",
   "metadata": {},
   "source": [
    "## Prepare the data for NLP & Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd787ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce Stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9355d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up each tweet into individual words.\n",
    "df2_token = [word_tokenize(_) for _ in df2]\n",
    "\n",
    "# Not viewing all output to reduce size of workbook\n",
    "# Just viewing one output instead\n",
    "df2_token[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all English words so we can exclude anything that doesn't appear on the list.\n",
    "all_english_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad1ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some pre-processing:\n",
    "# Get every word.\n",
    "# Convert it to lowercase.\n",
    "# Only include if the word is alphanumeric and if it is in the list of English words.\n",
    "\n",
    "df2_token_nostop =\\\n",
    "[[y.lower() for y in x if y.lower() not in stop_words and y.isalpha() and y.lower() in all_english_words]\\\n",
    " for x in df2_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View output\n",
    "df2_token_nostop[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb55c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable to store the Sentiment Intensity Analyser\n",
    "darth_vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through a dictionary comprehension to take every cleaned tweet. \n",
    "# Next run the polarity score function on the string.\n",
    "# This will return four values in a dictionary.\n",
    "\n",
    "df2_polarity =\\\n",
    "{\" \".join(_) : darth_vader.polarity_scores(\" \".join(_)) for _ in df2_token_nostop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionary results to a pandas dataframe. \n",
    "# The index is the cleaned tweet.\n",
    "\n",
    "polarity_pd = pd.DataFrame(df2_polarity).T\n",
    "\n",
    "# View the Dataframe\n",
    "polarity_pd\n",
    "\n",
    "# Compound score indicates actual sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0a552",
   "metadata": {},
   "source": [
    "### Visualising the data with Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8bdd9c",
   "metadata": {},
   "source": [
    "Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28432446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the output in a distribution\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_plot = polarity_pd.reset_index()['compound'].sort_values()\n",
    "ax1 = plt.axes()\n",
    "_plot.plot(kind='bar')\n",
    "\n",
    "x_axis = ax1.axes.get_xaxis()\n",
    "x_axis.set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ad3f3",
   "metadata": {},
   "source": [
    "- Most values are 0 (neutral) - blank spaces\n",
    "- More positive sentiment than negative sentiment amongst non-neutral values\n",
    "- Some very strong positive sentiment > 0.75\n",
    "- No very strong negative sentiment visible < -0.75\n",
    "\n",
    "A histogram plot will visualise the distribution of sentiment better although the strictly neutral values should be removed which will help make the histogram clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a951f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove polarity values equal to zero \n",
    "# This will improve the scale of the histogram and remove all strictly neutral reviews from the analysis\n",
    "# This will better highlight the distribution of polarity values = sentiment\n",
    "polarity_pd['compound'] = polarity_pd['compound'][polarity_pd['compound'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a944f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distribution of the sentiment analysis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot histogram of the polarity values with break at 0\n",
    "polarity_pd['compound'].hist(bins=[-1, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1],\n",
    "             ax=ax,\n",
    "             color=\"blue\")\n",
    "\n",
    "plt.title(\"Non Neutral Sentiments from most recent Tweets on Cycling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0130171",
   "metadata": {},
   "source": [
    "Top Words Visualised in a WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all words are stored in a list which can then be used to create a WordClod\n",
    "print(type(df2_token_nostop))\n",
    "\n",
    "# Confirmed words are in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ffe4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View list\n",
    "print(df2_token_nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286fc11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reformat list for use to generate wordcloud\n",
    "s = ''.join(str(x) for x in df2_token_nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d648dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Word Cloud\n",
    "wordcloud = (WordCloud(max_font_size=50, max_words=100, \n",
    "                       background_color=\"black\").generate(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f40731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customise the colouring\n",
    "bike = np.array(Image.open('bike.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5848e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Review: Display the WordCloud.\n",
    "wordcloud.generate(s)\n",
    "image_colors = ImageColorGenerator(bike)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off') \n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "\n",
    "# Ask Kevin to prettify if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7c38a",
   "metadata": {},
   "source": [
    "## Insights from Geo Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd224f75",
   "metadata": {},
   "source": [
    "Objective is to see where in the world Twitter users are most frequently discussing the topic of cycling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiting for Norah to input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b6456a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ad681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e5ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907b4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8f099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ab90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da2f9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6938e8ab",
   "metadata": {},
   "source": [
    "# Initial Insights from the count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4b136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52cda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869dfa9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cf9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48785ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbbf15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0996a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865bbca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4f18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcbd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aaa275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
